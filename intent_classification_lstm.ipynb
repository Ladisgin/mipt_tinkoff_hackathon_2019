{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import os\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nast1415/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/nast1415/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "#define stemmer\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename, delim):\n",
    "    df = pd.read_csv(filename, delimiter=delim)\n",
    "    # print(df.head())\n",
    "    intent = df.Intent\n",
    "    unique_intent = list(set(intent))\n",
    "    sentences = list(df[\"Sentence\"])\n",
    "  \n",
    "    return (intent, unique_intent, sentences)\n",
    "\n",
    "\n",
    "def cleaning(sentences):\n",
    "    words = []\n",
    "    for s in sentences:\n",
    "        clean = re.sub(r'[^ а-я А-Я a-z A-Z 0-9]', \" \", s)\n",
    "        w = word_tokenize(clean)\n",
    "        #stemming\n",
    "        words.append([i.lower() for i in w])\n",
    "    \n",
    "    return words  \n",
    "\n",
    "def create_tokenizer(words, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'):\n",
    "    token = Tokenizer(filters = filters)\n",
    "    token.fit_on_texts(words)\n",
    "    return token\n",
    "\n",
    "def max_length(words):\n",
    "    return(len(max(words, key = len)))\n",
    "\n",
    "def encoding_doc(token, words):\n",
    "    return(token.texts_to_sequences(words))\n",
    "\n",
    "def padding_doc(encoded_doc, max_length):\n",
    "    return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))\n",
    "\n",
    "def one_hot(encode):\n",
    "    o = OneHotEncoder(sparse = False)\n",
    "    return(o.fit_transform(encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "intent, unique_intent, sentences = load_dataset(\"hackaton/dataset.csv\", ',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rent_equipment',\n",
       " 'get_service',\n",
       " 'buy_sportswear',\n",
       " 'order_food',\n",
       " 'get_train',\n",
       " 'buy_food',\n",
       " 'buy_equipment',\n",
       " 'buy_or_order_goods',\n",
       " 'buy_sport_food']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53706\n"
     ]
    }
   ],
   "source": [
    "cleaned_words = cleaning(sentences)\n",
    "print(len(cleaned_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size = 1131 and Maximum length = 8\n"
     ]
    }
   ],
   "source": [
    "word_tokenizer = create_tokenizer(cleaned_words)\n",
    "vocab_size = len(word_tokenizer.word_index) + 1\n",
    "max_l = max_length(cleaned_words)\n",
    "\n",
    "print(\"Vocab Size = %d and Maximum length = %d\" % (vocab_size, max_l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_doc = encoding_doc(word_tokenizer, cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 9, 686],\n",
       " [1, 9, 687],\n",
       " [1, 9, 688],\n",
       " [1, 9, 689],\n",
       " [1, 9, 690, 691],\n",
       " [1, 9, 692, 693],\n",
       " [1, 9, 694],\n",
       " [1, 9, 695],\n",
       " [1, 9, 248],\n",
       " [1, 9, 696],\n",
       " [1, 9, 697],\n",
       " [1, 9, 698],\n",
       " [1, 9, 699, 700, 701],\n",
       " [1, 9, 702],\n",
       " [1, 9, 703],\n",
       " [1, 9, 704],\n",
       " [1, 9, 705],\n",
       " [1, 9, 706],\n",
       " [1, 9, 707],\n",
       " [1, 9, 708],\n",
       " [1, 9, 709],\n",
       " [1, 9, 710],\n",
       " [1, 9, 711],\n",
       " [1, 9, 712, 713],\n",
       " [1, 9, 714],\n",
       " [1, 9, 715],\n",
       " [1, 9, 716],\n",
       " [1, 9, 717],\n",
       " [1, 9, 718],\n",
       " [1, 9, 719],\n",
       " [1, 9, 720],\n",
       " [1, 9, 721],\n",
       " [1, 9, 722],\n",
       " [1, 9, 723, 724],\n",
       " [1, 9, 725],\n",
       " [1, 9, 726, 727],\n",
       " [1, 9, 728, 729],\n",
       " [1, 9, 730],\n",
       " [1, 9, 731],\n",
       " [1, 9, 732],\n",
       " [1, 9, 733],\n",
       " [1, 9, 734, 735],\n",
       " [1, 9, 736],\n",
       " [1, 9, 737],\n",
       " [1, 9, 738],\n",
       " [1, 9, 739],\n",
       " [1, 9, 740, 741],\n",
       " [1, 9, 742],\n",
       " [1, 9, 743],\n",
       " [1, 9, 744],\n",
       " [1, 9, 745],\n",
       " [1, 9, 746],\n",
       " [1, 9, 747],\n",
       " [1, 9, 748],\n",
       " [1, 9, 749],\n",
       " [1, 9, 750],\n",
       " [1, 9, 95],\n",
       " [1, 9, 48, 751],\n",
       " [1, 9, 249, 752],\n",
       " [1, 9, 250, 95],\n",
       " [1, 9, 96, 753],\n",
       " [1, 9, 251],\n",
       " [1, 9, 754, 97],\n",
       " [1, 9, 755],\n",
       " [1, 9, 756],\n",
       " [1, 9, 757],\n",
       " [1, 9, 758],\n",
       " [1, 9, 759],\n",
       " [1, 9, 760],\n",
       " [1, 9, 761],\n",
       " [1, 9, 19, 762],\n",
       " [1, 9, 763],\n",
       " [1, 9, 19, 252],\n",
       " [1, 9, 764],\n",
       " [1, 9, 765],\n",
       " [1, 9, 766],\n",
       " [1, 9, 767],\n",
       " [1, 9, 19, 768],\n",
       " [1, 9, 769],\n",
       " [1, 9, 770],\n",
       " [1, 9, 253],\n",
       " [1, 9, 771],\n",
       " [1, 9, 48, 772],\n",
       " [1, 9, 773],\n",
       " [1, 9, 774],\n",
       " [1, 9, 775, 254],\n",
       " [1, 9, 776],\n",
       " [1, 9, 96, 777],\n",
       " [1, 9, 778],\n",
       " [1, 9, 249, 34],\n",
       " [1, 9, 48, 34],\n",
       " [1, 9, 779, 34],\n",
       " [1, 9, 255, 34],\n",
       " [1, 9, 780, 34],\n",
       " [1, 9, 250, 34],\n",
       " [1, 9, 97],\n",
       " [1, 9, 19, 781],\n",
       " [1, 9, 782],\n",
       " [1, 9, 248, 783],\n",
       " [1, 9, 784],\n",
       " [1, 9, 785],\n",
       " [1, 9, 252],\n",
       " [1, 9, 786],\n",
       " [1, 9, 787],\n",
       " [1, 9, 788],\n",
       " [1, 9, 150],\n",
       " [1, 9, 789],\n",
       " [1, 9, 790],\n",
       " [1, 9, 73],\n",
       " [1, 9, 151],\n",
       " [1, 9, 791, 792],\n",
       " [1, 9, 793],\n",
       " [1, 9, 794, 31, 795],\n",
       " [1, 9, 98, 251],\n",
       " [1, 9, 796, 14, 150],\n",
       " [1, 9, 256],\n",
       " [1, 9, 797],\n",
       " [1, 9, 798],\n",
       " [1, 9, 799],\n",
       " [1, 9, 257],\n",
       " [1, 9, 292],\n",
       " [1, 9, 800],\n",
       " [1, 9, 801],\n",
       " [1, 9, 48],\n",
       " [1, 9, 99],\n",
       " [1, 9, 802],\n",
       " [1, 9, 803],\n",
       " [1, 9, 804],\n",
       " [1, 9, 805],\n",
       " [1, 9, 806],\n",
       " [1, 9, 807],\n",
       " [1, 9, 808, 258],\n",
       " [1, 9, 809],\n",
       " [1, 9, 810],\n",
       " [1, 9, 811],\n",
       " [1, 9, 812],\n",
       " [1, 9, 813],\n",
       " [1, 9, 814],\n",
       " [1, 9, 815],\n",
       " [1, 9, 816, 258],\n",
       " [1, 9, 817, 818],\n",
       " [1, 9, 819, 97],\n",
       " [1, 9, 95, 255],\n",
       " [1, 9, 820],\n",
       " [1, 9, 821],\n",
       " [1, 9, 822],\n",
       " [1, 9, 254],\n",
       " [1, 9, 253, 98],\n",
       " [1, 9, 256, 98],\n",
       " [1, 9, 259],\n",
       " [1, 9, 100, 31, 823],\n",
       " [1, 9, 100],\n",
       " [1, 9, 824],\n",
       " [1, 9, 825, 100],\n",
       " [1, 9, 74, 14, 826],\n",
       " [1, 9, 74, 14, 827],\n",
       " [1, 9, 828],\n",
       " [1, 9, 829],\n",
       " [1, 9, 830],\n",
       " [1, 9, 831],\n",
       " [1, 9, 832],\n",
       " [1, 9, 73],\n",
       " [1, 9, 260, 14, 833],\n",
       " [1, 9, 74, 31, 259],\n",
       " [1, 9, 834, 835],\n",
       " [1, 9, 32],\n",
       " [1, 9, 836, 32],\n",
       " [1, 9, 837],\n",
       " [1, 9, 838, 32],\n",
       " [1, 9, 839, 32],\n",
       " [1, 9, 840, 32],\n",
       " [1, 9, 841, 32],\n",
       " [1, 9, 842, 14, 32],\n",
       " [1, 9, 843, 260],\n",
       " [1, 9, 844],\n",
       " [1, 9, 845],\n",
       " [1, 9, 846],\n",
       " [1, 9, 49],\n",
       " [1, 9, 847],\n",
       " [1, 9, 848],\n",
       " [1, 9, 849],\n",
       " [1, 9, 850, 49],\n",
       " [1, 9, 851, 49],\n",
       " [1, 9, 852, 49],\n",
       " [1, 9, 90],\n",
       " [1, 9, 853],\n",
       " [1, 9, 49, 14, 293],\n",
       " [1, 9, 261],\n",
       " [1, 9, 854],\n",
       " [1, 9, 855],\n",
       " [1, 9, 856],\n",
       " [1, 9, 857],\n",
       " [1, 9, 858],\n",
       " [1, 9, 859],\n",
       " [1, 9, 860],\n",
       " [1, 9, 41, 261],\n",
       " [1, 9, 861],\n",
       " [1, 9, 862],\n",
       " [1, 9, 863],\n",
       " [1, 9, 101],\n",
       " [1, 9, 864],\n",
       " [1, 9, 865],\n",
       " [1, 9, 102, 866],\n",
       " [1, 9, 867, 102],\n",
       " [1, 9, 262, 263],\n",
       " [1, 9, 868, 103],\n",
       " [1, 9, 869, 103],\n",
       " [1, 9, 102, 103],\n",
       " [1, 9, 870],\n",
       " [1, 9, 264],\n",
       " [1, 9, 871, 264],\n",
       " [1, 9, 872, 14, 262, 263],\n",
       " [1, 9, 873],\n",
       " [1, 9, 257, 874],\n",
       " [1, 9, 875],\n",
       " [1, 9, 876],\n",
       " [1, 9, 877],\n",
       " [1, 9, 878],\n",
       " [1, 9, 879],\n",
       " [1, 9, 880],\n",
       " [1, 9, 881],\n",
       " [1, 9, 882],\n",
       " [1, 9, 883],\n",
       " [1, 9, 884],\n",
       " [1, 9, 885],\n",
       " [1, 9, 886, 91],\n",
       " [1, 9, 887, 888],\n",
       " [1, 9, 21],\n",
       " [1, 9, 99, 151],\n",
       " [1, 9, 889],\n",
       " [1, 9, 890],\n",
       " [1, 9, 891],\n",
       " [1, 9, 892],\n",
       " [1, 9, 893, 894],\n",
       " [1, 9, 895],\n",
       " [1, 9, 99, 265],\n",
       " [1, 9, 266],\n",
       " [1, 9, 896],\n",
       " [1, 9, 897],\n",
       " [1, 9, 87],\n",
       " [1, 9, 294],\n",
       " [1, 9, 898],\n",
       " [1, 9, 899],\n",
       " [1, 9, 152, 87],\n",
       " [1, 9, 900],\n",
       " [1, 9, 901],\n",
       " [1, 9, 902],\n",
       " [1, 9, 903],\n",
       " [1, 9, 904],\n",
       " [1, 9, 905],\n",
       " [1, 9, 906],\n",
       " [1, 9, 907, 908, 267],\n",
       " [1, 9, 909],\n",
       " [1, 9, 910, 911],\n",
       " [1, 9, 73, 14, 912, 913],\n",
       " [1, 9, 267],\n",
       " [1, 9, 914],\n",
       " [1, 9, 915],\n",
       " [1, 9, 916],\n",
       " [1, 9, 101, 14, 268],\n",
       " [1, 9, 269, 92],\n",
       " [1, 9, 917],\n",
       " [1, 9, 918],\n",
       " [1, 9, 919],\n",
       " [1, 9, 265],\n",
       " [1, 9, 74],\n",
       " [1, 9, 920],\n",
       " [1, 9, 921],\n",
       " [1, 9, 922],\n",
       " [1, 9, 923],\n",
       " [1, 9, 924],\n",
       " [1, 9, 104],\n",
       " [1, 9, 925],\n",
       " [1, 9, 96, 926],\n",
       " [1, 9, 927, 266],\n",
       " [1, 9, 928],\n",
       " [1, 9, 929],\n",
       " [1, 9, 930],\n",
       " [1, 9, 931],\n",
       " [1, 9, 932],\n",
       " [1, 9, 933],\n",
       " [1, 9, 934, 104],\n",
       " [1, 9, 935],\n",
       " [1, 9, 936],\n",
       " [1, 9, 937],\n",
       " [1, 9, 938],\n",
       " [1, 9, 48, 939],\n",
       " [1, 9, 940],\n",
       " [1, 9, 941, 52],\n",
       " [1, 9, 295],\n",
       " [1, 9, 942],\n",
       " [1, 9, 52],\n",
       " [1, 9, 52, 14, 153],\n",
       " [1, 9, 269, 155],\n",
       " [1, 9, 943, 52],\n",
       " [1, 9, 944],\n",
       " [1, 9, 55, 75],\n",
       " [1, 9, 88, 270],\n",
       " [1, 9, 270],\n",
       " [1, 9, 271],\n",
       " [1, 9, 945],\n",
       " [1, 9, 946],\n",
       " [1, 9, 271, 39, 947, 104],\n",
       " [1, 9, 948, 272],\n",
       " [1, 9, 272],\n",
       " [1, 9, 949],\n",
       " [1, 9, 950],\n",
       " [1, 9, 156, 40],\n",
       " [1, 9, 951],\n",
       " [1, 9, 952],\n",
       " [1, 9, 953],\n",
       " [1, 9, 954, 955],\n",
       " [1, 9, 956],\n",
       " [1, 9, 157, 38],\n",
       " [1, 9, 273, 38],\n",
       " [1, 9, 957, 76],\n",
       " [1, 9, 958, 76],\n",
       " [1, 9, 959, 158],\n",
       " [1, 9, 960],\n",
       " [1, 9, 961],\n",
       " [1, 9, 962, 72],\n",
       " [1, 9, 963, 76],\n",
       " [1, 9, 40, 88, 159],\n",
       " [1, 9, 274, 964],\n",
       " [1, 9, 274, 965],\n",
       " [1, 9, 966],\n",
       " [1, 9, 967],\n",
       " [1, 9, 160, 968],\n",
       " [1, 9, 969, 72],\n",
       " [1, 9, 970],\n",
       " [1, 9, 33],\n",
       " [1, 9, 275, 56],\n",
       " [1, 9, 971],\n",
       " [1, 9, 77, 972, 78],\n",
       " [1, 9, 973],\n",
       " [1, 9, 974, 975, 976],\n",
       " [1, 9, 977],\n",
       " [1, 9, 978],\n",
       " [1, 9, 276, 277],\n",
       " [1, 9, 277],\n",
       " [1, 9, 979],\n",
       " [1, 9, 37],\n",
       " [1, 9, 37, 980],\n",
       " [1, 9, 37, 981],\n",
       " [1, 9, 37, 982],\n",
       " [1, 9, 37, 983],\n",
       " [1, 9, 984],\n",
       " [1, 9, 985],\n",
       " [1, 9, 986],\n",
       " [1, 9, 987],\n",
       " [1, 9, 988],\n",
       " [1, 9, 989, 161],\n",
       " [1, 9, 14, 990, 57, 278],\n",
       " [1, 9, 58, 991],\n",
       " [1, 9, 58, 992],\n",
       " [1, 9, 58, 993],\n",
       " [1, 9, 994],\n",
       " [1, 9, 995],\n",
       " [1, 9, 996, 22],\n",
       " [1, 9, 43],\n",
       " [1, 9, 997],\n",
       " [1, 9, 14, 998],\n",
       " [1, 9, 14, 999],\n",
       " [1, 9, 14, 1000],\n",
       " [1, 9, 14, 1001],\n",
       " [1, 9, 14, 1002],\n",
       " [1, 9, 14, 1003],\n",
       " [1, 9, 279, 1004, 1005],\n",
       " [1, 9, 55, 75, 14, 1006, 1007],\n",
       " [1, 9, 279, 1008],\n",
       " [1, 9, 1009, 1010],\n",
       " [1, 9, 1011, 152],\n",
       " [1, 9, 1012],\n",
       " [1, 9, 1013],\n",
       " [1, 9, 162],\n",
       " [1, 9, 1014],\n",
       " [1, 9, 1015],\n",
       " [1, 9, 1016],\n",
       " [1, 9, 1017],\n",
       " [1, 9, 1018, 89],\n",
       " [1, 9, 1019, 1020],\n",
       " [1, 9, 89],\n",
       " [1, 9, 1021],\n",
       " [1, 9, 1022],\n",
       " [1, 9, 1023, 1024],\n",
       " [1, 9, 163, 1025],\n",
       " [1, 9, 1026, 1027],\n",
       " [1, 9, 1028],\n",
       " [1, 9, 1029, 1030],\n",
       " [1, 9, 1031, 1032],\n",
       " [1, 9, 1033],\n",
       " [1, 9, 280, 14, 41, 164, 50],\n",
       " [1, 9, 1034],\n",
       " [1, 9, 281, 75],\n",
       " [1, 9, 1035, 1036],\n",
       " [1, 9, 280, 39, 1037, 1038],\n",
       " [1, 9, 1039, 282],\n",
       " [1, 9, 282],\n",
       " [1, 9, 56],\n",
       " [1, 9, 56, 275, 1040],\n",
       " [1, 9, 1041, 1042, 154],\n",
       " [1, 9, 19, 1043],\n",
       " [1, 9, 101, 14, 283, 57, 268],\n",
       " [1, 9, 283],\n",
       " [1, 9, 27],\n",
       " [1, 9, 19, 27],\n",
       " [1, 9, 165],\n",
       " [1, 9, 1044],\n",
       " [1, 9, 27, 284],\n",
       " [1, 9, 27, 14, 285, 43],\n",
       " [1, 9, 286, 27],\n",
       " [1, 9, 286, 287],\n",
       " [1, 9, 19, 55, 75],\n",
       " [1, 9, 1045, 1046, 76],\n",
       " [1, 9, 166, 288],\n",
       " [1, 9, 1047],\n",
       " [1, 9, 1048],\n",
       " [1, 9, 1049],\n",
       " [1, 9, 1050],\n",
       " [1, 9, 38],\n",
       " [1, 9, 41, 19, 22],\n",
       " [1, 9, 1051, 22],\n",
       " [1, 9, 19, 22],\n",
       " [1, 9, 41, 50],\n",
       " [1, 9, 285, 43],\n",
       " [1, 9, 288],\n",
       " [1, 9, 1052],\n",
       " [1, 9, 19, 287],\n",
       " [1, 9, 284, 22],\n",
       " [1, 9, 73],\n",
       " [1, 9, 1053, 1054],\n",
       " [1, 9, 281, 105],\n",
       " [1, 9, 1055],\n",
       " [1, 9, 1056],\n",
       " [1, 9, 1057],\n",
       " [1, 9, 1058, 1059, 1060],\n",
       " [1, 9, 1061, 289],\n",
       " [1, 9, 1062],\n",
       " [1, 9, 1063, 290],\n",
       " [1, 9, 14, 296],\n",
       " [1, 9, 1064],\n",
       " [1, 9, 1065, 105],\n",
       " [1, 9, 289],\n",
       " [1, 9, 276],\n",
       " [1, 9, 291],\n",
       " [1, 9, 1066, 291],\n",
       " [1, 9, 1067],\n",
       " [1, 9, 1068],\n",
       " [1, 9, 79],\n",
       " [1, 9, 1069],\n",
       " [1, 9, 42],\n",
       " [1, 9, 1070, 1071],\n",
       " [1, 9, 1072, 1073, 105],\n",
       " [1, 9, 290],\n",
       " [1, 9, 273, 1074, 1075, 1076],\n",
       " [1, 9, 14, 278, 57, 1077],\n",
       " [1, 9, 1078, 1079],\n",
       " [1, 10, 686],\n",
       " [1, 10, 687],\n",
       " [1, 10, 688],\n",
       " [1, 10, 689],\n",
       " [1, 10, 690, 691],\n",
       " [1, 10, 692, 693],\n",
       " [1, 10, 694],\n",
       " [1, 10, 695],\n",
       " [1, 10, 248],\n",
       " [1, 10, 696],\n",
       " [1, 10, 697],\n",
       " [1, 10, 698],\n",
       " [1, 10, 699, 700, 701],\n",
       " [1, 10, 702],\n",
       " [1, 10, 703],\n",
       " [1, 10, 704],\n",
       " [1, 10, 705],\n",
       " [1, 10, 706],\n",
       " [1, 10, 707],\n",
       " [1, 10, 708],\n",
       " [1, 10, 709],\n",
       " [1, 10, 710],\n",
       " [1, 10, 711],\n",
       " [1, 10, 712, 713],\n",
       " [1, 10, 714],\n",
       " [1, 10, 715],\n",
       " [1, 10, 716],\n",
       " [1, 10, 717],\n",
       " [1, 10, 718],\n",
       " [1, 10, 719],\n",
       " [1, 10, 720],\n",
       " [1, 10, 721],\n",
       " [1, 10, 722],\n",
       " [1, 10, 723, 724],\n",
       " [1, 10, 725],\n",
       " [1, 10, 726, 727],\n",
       " [1, 10, 728, 729],\n",
       " [1, 10, 730],\n",
       " [1, 10, 731],\n",
       " [1, 10, 732],\n",
       " [1, 10, 733],\n",
       " [1, 10, 734, 735],\n",
       " [1, 10, 736],\n",
       " [1, 10, 737],\n",
       " [1, 10, 738],\n",
       " [1, 10, 739],\n",
       " [1, 10, 740, 741],\n",
       " [1, 10, 742],\n",
       " [1, 10, 743],\n",
       " [1, 10, 744],\n",
       " [1, 10, 745],\n",
       " [1, 10, 746],\n",
       " [1, 10, 747],\n",
       " [1, 10, 748],\n",
       " [1, 10, 749],\n",
       " [1, 10, 750],\n",
       " [1, 10, 95],\n",
       " [1, 10, 48, 751],\n",
       " [1, 10, 249, 752],\n",
       " [1, 10, 250, 95],\n",
       " [1, 10, 96, 753],\n",
       " [1, 10, 251],\n",
       " [1, 10, 754, 97],\n",
       " [1, 10, 755],\n",
       " [1, 10, 756],\n",
       " [1, 10, 757],\n",
       " [1, 10, 758],\n",
       " [1, 10, 759],\n",
       " [1, 10, 760],\n",
       " [1, 10, 761],\n",
       " [1, 10, 19, 762],\n",
       " [1, 10, 763],\n",
       " [1, 10, 19, 252],\n",
       " [1, 10, 764],\n",
       " [1, 10, 765],\n",
       " [1, 10, 766],\n",
       " [1, 10, 767],\n",
       " [1, 10, 19, 768],\n",
       " [1, 10, 769],\n",
       " [1, 10, 770],\n",
       " [1, 10, 253],\n",
       " [1, 10, 771],\n",
       " [1, 10, 48, 772],\n",
       " [1, 10, 773],\n",
       " [1, 10, 774],\n",
       " [1, 10, 775, 254],\n",
       " [1, 10, 776],\n",
       " [1, 10, 96, 777],\n",
       " [1, 10, 778],\n",
       " [1, 10, 249, 34],\n",
       " [1, 10, 48, 34],\n",
       " [1, 10, 779, 34],\n",
       " [1, 10, 255, 34],\n",
       " [1, 10, 780, 34],\n",
       " [1, 10, 250, 34],\n",
       " [1, 10, 97],\n",
       " [1, 10, 19, 781],\n",
       " [1, 10, 782],\n",
       " [1, 10, 248, 783],\n",
       " [1, 10, 784],\n",
       " [1, 10, 785],\n",
       " [1, 10, 252],\n",
       " [1, 10, 786],\n",
       " [1, 10, 787],\n",
       " [1, 10, 788],\n",
       " [1, 10, 150],\n",
       " [1, 10, 789],\n",
       " [1, 10, 790],\n",
       " [1, 10, 73],\n",
       " [1, 10, 151],\n",
       " [1, 10, 791, 792],\n",
       " [1, 10, 793],\n",
       " [1, 10, 794, 31, 795],\n",
       " [1, 10, 98, 251],\n",
       " [1, 10, 796, 14, 150],\n",
       " [1, 10, 256],\n",
       " [1, 10, 797],\n",
       " [1, 10, 798],\n",
       " [1, 10, 799],\n",
       " [1, 10, 257],\n",
       " [1, 10, 292],\n",
       " [1, 10, 800],\n",
       " [1, 10, 801],\n",
       " [1, 10, 48],\n",
       " [1, 10, 99],\n",
       " [1, 10, 802],\n",
       " [1, 10, 803],\n",
       " [1, 10, 804],\n",
       " [1, 10, 805],\n",
       " [1, 10, 806],\n",
       " [1, 10, 807],\n",
       " [1, 10, 808, 258],\n",
       " [1, 10, 809],\n",
       " [1, 10, 810],\n",
       " [1, 10, 811],\n",
       " [1, 10, 812],\n",
       " [1, 10, 813],\n",
       " [1, 10, 814],\n",
       " [1, 10, 815],\n",
       " [1, 10, 816, 258],\n",
       " [1, 10, 817, 818],\n",
       " [1, 10, 819, 97],\n",
       " [1, 10, 95, 255],\n",
       " [1, 10, 820],\n",
       " [1, 10, 821],\n",
       " [1, 10, 822],\n",
       " [1, 10, 254],\n",
       " [1, 10, 253, 98],\n",
       " [1, 10, 256, 98],\n",
       " [1, 10, 259],\n",
       " [1, 10, 100, 31, 823],\n",
       " [1, 10, 100],\n",
       " [1, 10, 824],\n",
       " [1, 10, 825, 100],\n",
       " [1, 10, 74, 14, 826],\n",
       " [1, 10, 74, 14, 827],\n",
       " [1, 10, 828],\n",
       " [1, 10, 829],\n",
       " [1, 10, 830],\n",
       " [1, 10, 831],\n",
       " [1, 10, 832],\n",
       " [1, 10, 73],\n",
       " [1, 10, 260, 14, 833],\n",
       " [1, 10, 74, 31, 259],\n",
       " [1, 10, 834, 835],\n",
       " [1, 10, 32],\n",
       " [1, 10, 836, 32],\n",
       " [1, 10, 837],\n",
       " [1, 10, 838, 32],\n",
       " [1, 10, 839, 32],\n",
       " [1, 10, 840, 32],\n",
       " [1, 10, 841, 32],\n",
       " [1, 10, 842, 14, 32],\n",
       " [1, 10, 843, 260],\n",
       " [1, 10, 844],\n",
       " [1, 10, 845],\n",
       " [1, 10, 846],\n",
       " [1, 10, 49],\n",
       " [1, 10, 847],\n",
       " [1, 10, 848],\n",
       " [1, 10, 849],\n",
       " [1, 10, 850, 49],\n",
       " [1, 10, 851, 49],\n",
       " [1, 10, 852, 49],\n",
       " [1, 10, 90],\n",
       " [1, 10, 853],\n",
       " [1, 10, 49, 14, 293],\n",
       " [1, 10, 261],\n",
       " [1, 10, 854],\n",
       " [1, 10, 855],\n",
       " [1, 10, 856],\n",
       " [1, 10, 857],\n",
       " [1, 10, 858],\n",
       " [1, 10, 859],\n",
       " [1, 10, 860],\n",
       " [1, 10, 41, 261],\n",
       " [1, 10, 861],\n",
       " [1, 10, 862],\n",
       " [1, 10, 863],\n",
       " [1, 10, 101],\n",
       " [1, 10, 864],\n",
       " [1, 10, 865],\n",
       " [1, 10, 102, 866],\n",
       " [1, 10, 867, 102],\n",
       " [1, 10, 262, 263],\n",
       " [1, 10, 868, 103],\n",
       " [1, 10, 869, 103],\n",
       " [1, 10, 102, 103],\n",
       " [1, 10, 870],\n",
       " [1, 10, 264],\n",
       " [1, 10, 871, 264],\n",
       " [1, 10, 872, 14, 262, 263],\n",
       " [1, 10, 873],\n",
       " [1, 10, 257, 874],\n",
       " [1, 10, 875],\n",
       " [1, 10, 876],\n",
       " [1, 10, 877],\n",
       " [1, 10, 878],\n",
       " [1, 10, 879],\n",
       " [1, 10, 880],\n",
       " [1, 10, 881],\n",
       " [1, 10, 882],\n",
       " [1, 10, 883],\n",
       " [1, 10, 884],\n",
       " [1, 10, 885],\n",
       " [1, 10, 886, 91],\n",
       " [1, 10, 887, 888],\n",
       " [1, 10, 21],\n",
       " [1, 10, 99, 151],\n",
       " [1, 10, 889],\n",
       " [1, 10, 890],\n",
       " [1, 10, 891],\n",
       " [1, 10, 892],\n",
       " [1, 10, 893, 894],\n",
       " [1, 10, 895],\n",
       " [1, 10, 99, 265],\n",
       " [1, 10, 266],\n",
       " [1, 10, 896],\n",
       " [1, 10, 897],\n",
       " [1, 10, 87],\n",
       " [1, 10, 294],\n",
       " [1, 10, 898],\n",
       " [1, 10, 899],\n",
       " [1, 10, 152, 87],\n",
       " [1, 10, 900],\n",
       " [1, 10, 901],\n",
       " [1, 10, 902],\n",
       " [1, 10, 903],\n",
       " [1, 10, 904],\n",
       " [1, 10, 905],\n",
       " [1, 10, 906],\n",
       " [1, 10, 907, 908, 267],\n",
       " [1, 10, 909],\n",
       " [1, 10, 910, 911],\n",
       " [1, 10, 73, 14, 912, 913],\n",
       " [1, 10, 267],\n",
       " [1, 10, 914],\n",
       " [1, 10, 915],\n",
       " [1, 10, 916],\n",
       " [1, 10, 101, 14, 268],\n",
       " [1, 10, 269, 92],\n",
       " [1, 10, 917],\n",
       " [1, 10, 918],\n",
       " [1, 10, 919],\n",
       " [1, 10, 265],\n",
       " [1, 10, 74],\n",
       " [1, 10, 920],\n",
       " [1, 10, 921],\n",
       " [1, 10, 922],\n",
       " [1, 10, 923],\n",
       " [1, 10, 924],\n",
       " [1, 10, 104],\n",
       " [1, 10, 925],\n",
       " [1, 10, 96, 926],\n",
       " [1, 10, 927, 266],\n",
       " [1, 10, 928],\n",
       " [1, 10, 929],\n",
       " [1, 10, 930],\n",
       " [1, 10, 931],\n",
       " [1, 10, 932],\n",
       " [1, 10, 933],\n",
       " [1, 10, 934, 104],\n",
       " [1, 10, 935],\n",
       " [1, 10, 936],\n",
       " [1, 10, 937],\n",
       " [1, 10, 938],\n",
       " [1, 10, 48, 939],\n",
       " [1, 10, 940],\n",
       " [1, 10, 941, 52],\n",
       " [1, 10, 295],\n",
       " [1, 10, 942],\n",
       " [1, 10, 52],\n",
       " [1, 10, 52, 14, 153],\n",
       " [1, 10, 269, 155],\n",
       " [1, 10, 943, 52],\n",
       " [1, 10, 944],\n",
       " [1, 10, 55, 75],\n",
       " [1, 10, 88, 270],\n",
       " [1, 10, 270],\n",
       " [1, 10, 271],\n",
       " [1, 10, 945],\n",
       " [1, 10, 946],\n",
       " [1, 10, 271, 39, 947, 104],\n",
       " [1, 10, 948, 272],\n",
       " [1, 10, 272],\n",
       " [1, 10, 949],\n",
       " [1, 10, 950],\n",
       " [1, 10, 156, 40],\n",
       " [1, 10, 951],\n",
       " [1, 10, 952],\n",
       " [1, 10, 953],\n",
       " [1, 10, 954, 955],\n",
       " [1, 10, 956],\n",
       " [1, 10, 157, 38],\n",
       " [1, 10, 273, 38],\n",
       " [1, 10, 957, 76],\n",
       " [1, 10, 958, 76],\n",
       " [1, 10, 959, 158],\n",
       " [1, 10, 960],\n",
       " [1, 10, 961],\n",
       " [1, 10, 962, 72],\n",
       " [1, 10, 963, 76],\n",
       " [1, 10, 40, 88, 159],\n",
       " [1, 10, 274, 964],\n",
       " [1, 10, 274, 965],\n",
       " [1, 10, 966],\n",
       " [1, 10, 967],\n",
       " [1, 10, 160, 968],\n",
       " [1, 10, 969, 72],\n",
       " [1, 10, 970],\n",
       " [1, 10, 33],\n",
       " [1, 10, 275, 56],\n",
       " [1, 10, 971],\n",
       " [1, 10, 77, 972, 78],\n",
       " [1, 10, 973],\n",
       " [1, 10, 974, 975, 976],\n",
       " [1, 10, 977],\n",
       " [1, 10, 978],\n",
       " [1, 10, 276, 277],\n",
       " [1, 10, 277],\n",
       " [1, 10, 979],\n",
       " [1, 10, 37],\n",
       " [1, 10, 37, 980],\n",
       " [1, 10, 37, 981],\n",
       " [1, 10, 37, 982],\n",
       " [1, 10, 37, 983],\n",
       " [1, 10, 984],\n",
       " [1, 10, 985],\n",
       " [1, 10, 986],\n",
       " [1, 10, 987],\n",
       " [1, 10, 988],\n",
       " [1, 10, 989, 161],\n",
       " [1, 10, 14, 990, 57, 278],\n",
       " [1, 10, 58, 991],\n",
       " [1, 10, 58, 992],\n",
       " [1, 10, 58, 993],\n",
       " [1, 10, 994],\n",
       " [1, 10, 995],\n",
       " [1, 10, 996, 22],\n",
       " [1, 10, 43],\n",
       " [1, 10, 997],\n",
       " [1, 10, 14, 998],\n",
       " [1, 10, 14, 999],\n",
       " [1, 10, 14, 1000],\n",
       " [1, 10, 14, 1001],\n",
       " [1, 10, 14, 1002],\n",
       " [1, 10, 14, 1003],\n",
       " [1, 10, 279, 1004, 1005],\n",
       " [1, 10, 55, 75, 14, 1006, 1007],\n",
       " [1, 10, 279, 1008],\n",
       " [1, 10, 1009, 1010],\n",
       " [1, 10, 1011, 152],\n",
       " [1, 10, 1012],\n",
       " [1, 10, 1013],\n",
       " [1, 10, 162],\n",
       " [1, 10, 1014],\n",
       " [1, 10, 1015],\n",
       " [1, 10, 1016],\n",
       " [1, 10, 1017],\n",
       " [1, 10, 1018, 89],\n",
       " [1, 10, 1019, 1020],\n",
       " [1, 10, 89],\n",
       " [1, 10, 1021],\n",
       " [1, 10, 1022],\n",
       " [1, 10, 1023, 1024],\n",
       " [1, 10, 163, 1025],\n",
       " [1, 10, 1026, 1027],\n",
       " [1, 10, 1028],\n",
       " [1, 10, 1029, 1030],\n",
       " [1, 10, 1031, 1032],\n",
       " [1, 10, 1033],\n",
       " [1, 10, 280, 14, 41, 164, 50],\n",
       " [1, 10, 1034],\n",
       " [1, 10, 281, 75],\n",
       " [1, 10, 1035, 1036],\n",
       " [1, 10, 280, 39, 1037, 1038],\n",
       " [1, 10, 1039, 282],\n",
       " [1, 10, 282],\n",
       " [1, 10, 56],\n",
       " [1, 10, 56, 275, 1040],\n",
       " [1, 10, 1041, 1042, 154],\n",
       " [1, 10, 19, 1043],\n",
       " [1, 10, 101, 14, 283, 57, 268],\n",
       " [1, 10, 283],\n",
       " [1, 10, 27],\n",
       " [1, 10, 19, 27],\n",
       " [1, 10, 165],\n",
       " [1, 10, 1044],\n",
       " [1, 10, 27, 284],\n",
       " [1, 10, 27, 14, 285, 43],\n",
       " [1, 10, 286, 27],\n",
       " [1, 10, 286, 287],\n",
       " [1, 10, 19, 55, 75],\n",
       " [1, 10, 1045, 1046, 76],\n",
       " [1, 10, 166, 288],\n",
       " [1, 10, 1047],\n",
       " [1, 10, 1048],\n",
       " [1, 10, 1049],\n",
       " [1, 10, 1050],\n",
       " [1, 10, 38],\n",
       " [1, 10, 41, 19, 22],\n",
       " [1, 10, 1051, 22],\n",
       " [1, 10, 19, 22],\n",
       " [1, 10, 41, 50],\n",
       " [1, 10, 285, 43],\n",
       " [1, 10, 288],\n",
       " [1, 10, 1052],\n",
       " [1, 10, 19, 287],\n",
       " [1, 10, 284, 22],\n",
       " [1, 10, 73],\n",
       " [1, 10, 1053, 1054],\n",
       " [1, 10, 281, 105],\n",
       " [1, 10, 1055],\n",
       " [1, 10, 1056],\n",
       " [1, 10, 1057],\n",
       " [1, 10, 1058, 1059, 1060],\n",
       " [1, 10, 1061, 289],\n",
       " [1, 10, 1062],\n",
       " [1, 10, 1063, 290],\n",
       " [1, 10, 14, 296],\n",
       " [1, 10, 1064],\n",
       " [1, 10, 1065, 105],\n",
       " [1, 10, 289],\n",
       " [1, 10, 276],\n",
       " [1, 10, 291],\n",
       " [1, 10, 1066, 291],\n",
       " [1, 10, 1067],\n",
       " [1, 10, 1068],\n",
       " [1, 10, 79],\n",
       " [1, 10, 1069],\n",
       " [1, 10, 42],\n",
       " [1, 10, 1070, 1071],\n",
       " [1, 10, 1072, 1073, 105],\n",
       " [1, 10, 290],\n",
       " [1, 10, 273, 1074, 1075, 1076],\n",
       " [1, 10, 14, 278, 57, 1077],\n",
       " [1, 10, 1078, 1079],\n",
       " [1, 6, 686],\n",
       " [1, 6, 687],\n",
       " [1, 6, 688],\n",
       " [1, 6, 689],\n",
       " [1, 6, 690, 691],\n",
       " [1, 6, 692, 693],\n",
       " [1, 6, 694],\n",
       " [1, 6, 695],\n",
       " [1, 6, 248],\n",
       " [1, 6, 696],\n",
       " [1, 6, 697],\n",
       " [1, 6, 698],\n",
       " [1, 6, 699, 700, 701],\n",
       " [1, 6, 702],\n",
       " [1, 6, 703],\n",
       " [1, 6, 704],\n",
       " [1, 6, 705],\n",
       " [1, 6, 706],\n",
       " [1, 6, 707],\n",
       " [1, 6, 708],\n",
       " [1, 6, 709],\n",
       " [1, 6, 710],\n",
       " [1, 6, 711],\n",
       " [1, 6, 712, 713],\n",
       " [1, 6, 714],\n",
       " [1, 6, 715],\n",
       " [1, 6, 716],\n",
       " [1, 6, 717],\n",
       " [1, 6, 718],\n",
       " [1, 6, 719],\n",
       " [1, 6, 720],\n",
       " [1, 6, 721],\n",
       " [1, 6, 722],\n",
       " [1, 6, 723, 724],\n",
       " [1, 6, 725],\n",
       " [1, 6, 726, 727],\n",
       " [1, 6, 728, 729],\n",
       " [1, 6, 730],\n",
       " [1, 6, 731],\n",
       " [1, 6, 732],\n",
       " [1, 6, 733],\n",
       " [1, 6, 734, 735],\n",
       " [1, 6, 736],\n",
       " [1, 6, 737],\n",
       " [1, 6, 738],\n",
       " [1, 6, 739],\n",
       " [1, 6, 740, 741],\n",
       " [1, 6, 742],\n",
       " [1, 6, 743],\n",
       " [1, 6, 744],\n",
       " [1, 6, 745],\n",
       " [1, 6, 746],\n",
       " [1, 6, 747],\n",
       " [1, 6, 748],\n",
       " [1, 6, 749],\n",
       " [1, 6, 750],\n",
       " [1, 6, 95],\n",
       " [1, 6, 48, 751],\n",
       " [1, 6, 249, 752],\n",
       " [1, 6, 250, 95],\n",
       " [1, 6, 96, 753],\n",
       " [1, 6, 251],\n",
       " [1, 6, 754, 97],\n",
       " [1, 6, 755],\n",
       " [1, 6, 756],\n",
       " [1, 6, 757],\n",
       " [1, 6, 758],\n",
       " [1, 6, 759],\n",
       " [1, 6, 760],\n",
       " [1, 6, 761],\n",
       " [1, 6, 19, 762],\n",
       " [1, 6, 763],\n",
       " [1, 6, 19, 252],\n",
       " [1, 6, 764],\n",
       " [1, 6, 765],\n",
       " [1, 6, 766],\n",
       " [1, 6, 767],\n",
       " [1, 6, 19, 768],\n",
       " [1, 6, 769],\n",
       " [1, 6, 770],\n",
       " [1, 6, 253],\n",
       " [1, 6, 771],\n",
       " [1, 6, 48, 772],\n",
       " [1, 6, 773],\n",
       " [1, 6, 774],\n",
       " [1, 6, 775, 254],\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_doc = padding_doc(encoded_doc, max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   9, 686, ...,   0,   0,   0],\n",
       "       [  1,   9, 687, ...,   0,   0,   0],\n",
       "       [  1,   9, 688, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [247,   0,   0, ...,   0,   0,   0],\n",
       "       [684,   0,   0, ...,   0,   0,   0],\n",
       "       [685,   0,   0, ...,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of padded docs =  (53706, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of padded docs = \",padded_doc.shape)\n",
    "#tokenizer with filter changed\n",
    "output_tokenizer = create_tokenizer(unique_intent, filters = '!\"#$%&()*+,-/:;<=>?@[\\]^`{|}~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buy_equipment': 7,\n",
       " 'buy_food': 6,\n",
       " 'buy_or_order_goods': 8,\n",
       " 'buy_sport_food': 9,\n",
       " 'buy_sportswear': 3,\n",
       " 'get_service': 2,\n",
       " 'get_train': 5,\n",
       " 'order_food': 4,\n",
       " 'rent_equipment': 1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_output = encoding_doc(output_tokenizer, intent)\n",
    "encoded_output = np.array(encoded_output).reshape(len(encoded_output), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53706, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nast1415/.local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "output_one_hot = one_hot(encoded_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53706, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_model(vocab_size, max_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 128, input_length = max_length, trainable = False))\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    # model.add(LSTM(128))\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    # TODO: вместо 2 количество классов представленных в выборке\n",
    "    model.add(Dense(9, activation = \"softmax\"))\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X = (42964, 8) and train_Y = (42964, 9)\n",
      "Shape of val_X = (10742, 8) and val_Y = (10742, 9)\n"
     ]
    }
   ],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(padded_doc, output_one_hot, shuffle = True, test_size = 0.2)\n",
    "print(\"Shape of train_X = %s and train_Y = %s\" % (train_X.shape, train_Y.shape))\n",
    "print(\"Shape of val_X = %s and val_Y = %s\" % (val_X.shape, val_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 8, 128)            144768    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 297       \n",
      "=================================================================\n",
      "Total params: 416,457\n",
      "Trainable params: 271,689\n",
      "Non-trainable params: 144,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size, max_l)\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [metrics.categorical_accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42964, 9)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42964 samples, validate on 10742 samples\n",
      "Epoch 1/200\n",
      "42964/42964 [==============================] - 17s 390us/step - loss: 1.4984 - categorical_accuracy: 0.4803 - val_loss: 1.2575 - val_categorical_accuracy: 0.5209\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.25746, saving model to model.h5\n",
      "Epoch 2/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 1.2647 - categorical_accuracy: 0.5191 - val_loss: 1.1525 - val_categorical_accuracy: 0.5445\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.25746 to 1.15252, saving model to model.h5\n",
      "Epoch 3/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 1.1625 - categorical_accuracy: 0.5491 - val_loss: 1.0686 - val_categorical_accuracy: 0.5722\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.15252 to 1.06859, saving model to model.h5\n",
      "Epoch 4/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 1.0690 - categorical_accuracy: 0.5803 - val_loss: 0.9579 - val_categorical_accuracy: 0.6098\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.06859 to 0.95790, saving model to model.h5\n",
      "Epoch 5/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.9618 - categorical_accuracy: 0.6165 - val_loss: 0.8522 - val_categorical_accuracy: 0.6480\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.95790 to 0.85224, saving model to model.h5\n",
      "Epoch 6/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.8618 - categorical_accuracy: 0.6530 - val_loss: 0.7330 - val_categorical_accuracy: 0.7002\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.85224 to 0.73298, saving model to model.h5\n",
      "Epoch 7/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.7503 - categorical_accuracy: 0.6959 - val_loss: 0.6235 - val_categorical_accuracy: 0.7374\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.73298 to 0.62349, saving model to model.h5\n",
      "Epoch 8/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.6413 - categorical_accuracy: 0.7339 - val_loss: 0.5246 - val_categorical_accuracy: 0.7687\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.62349 to 0.52457, saving model to model.h5\n",
      "Epoch 9/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.5696 - categorical_accuracy: 0.7555 - val_loss: 0.4729 - val_categorical_accuracy: 0.7872\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.52457 to 0.47294, saving model to model.h5\n",
      "Epoch 10/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.5180 - categorical_accuracy: 0.7744 - val_loss: 0.4538 - val_categorical_accuracy: 0.7972\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.47294 to 0.45378, saving model to model.h5\n",
      "Epoch 11/200\n",
      "42964/42964 [==============================] - 16s 376us/step - loss: 0.4694 - categorical_accuracy: 0.7927 - val_loss: 0.3690 - val_categorical_accuracy: 0.8271\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.45378 to 0.36899, saving model to model.h5\n",
      "Epoch 12/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.4257 - categorical_accuracy: 0.8100 - val_loss: 0.3302 - val_categorical_accuracy: 0.8438\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36899 to 0.33019, saving model to model.h5\n",
      "Epoch 13/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.3784 - categorical_accuracy: 0.8281 - val_loss: 0.2986 - val_categorical_accuracy: 0.8532\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33019 to 0.29857, saving model to model.h5\n",
      "Epoch 14/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.3469 - categorical_accuracy: 0.8407 - val_loss: 0.2579 - val_categorical_accuracy: 0.8743\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.29857 to 0.25788, saving model to model.h5\n",
      "Epoch 15/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.3075 - categorical_accuracy: 0.8593 - val_loss: 0.2290 - val_categorical_accuracy: 0.8828\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.25788 to 0.22897, saving model to model.h5\n",
      "Epoch 16/200\n",
      "42964/42964 [==============================] - 16s 361us/step - loss: 0.2844 - categorical_accuracy: 0.8676 - val_loss: 0.2060 - val_categorical_accuracy: 0.8968\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.22897 to 0.20596, saving model to model.h5\n",
      "Epoch 17/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.2541 - categorical_accuracy: 0.8783 - val_loss: 0.1805 - val_categorical_accuracy: 0.9039\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.20596 to 0.18048, saving model to model.h5\n",
      "Epoch 18/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.2395 - categorical_accuracy: 0.8837 - val_loss: 0.1737 - val_categorical_accuracy: 0.9048\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.18048 to 0.17370, saving model to model.h5\n",
      "Epoch 19/200\n",
      "42964/42964 [==============================] - 16s 361us/step - loss: 0.2331 - categorical_accuracy: 0.8859 - val_loss: 0.1679 - val_categorical_accuracy: 0.9050\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.17370 to 0.16791, saving model to model.h5\n",
      "Epoch 20/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.2149 - categorical_accuracy: 0.8924 - val_loss: 0.1785 - val_categorical_accuracy: 0.9047\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16791\n",
      "Epoch 21/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.2092 - categorical_accuracy: 0.8939 - val_loss: 0.1498 - val_categorical_accuracy: 0.9142\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.16791 to 0.14978, saving model to model.h5\n",
      "Epoch 22/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.2039 - categorical_accuracy: 0.8960 - val_loss: 0.1589 - val_categorical_accuracy: 0.9111\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.14978\n",
      "Epoch 23/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1969 - categorical_accuracy: 0.8987 - val_loss: 0.1645 - val_categorical_accuracy: 0.9131\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.14978\n",
      "Epoch 24/200\n",
      "42964/42964 [==============================] - 15s 359us/step - loss: 0.1984 - categorical_accuracy: 0.8989 - val_loss: 0.1586 - val_categorical_accuracy: 0.9132\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.14978\n",
      "Epoch 25/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1788 - categorical_accuracy: 0.9042 - val_loss: 0.1723 - val_categorical_accuracy: 0.9094\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.14978\n",
      "Epoch 26/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1899 - categorical_accuracy: 0.9019 - val_loss: 0.1422 - val_categorical_accuracy: 0.9138\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.14978 to 0.14224, saving model to model.h5\n",
      "Epoch 27/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1708 - categorical_accuracy: 0.9077 - val_loss: 0.1431 - val_categorical_accuracy: 0.9129\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.14224\n",
      "Epoch 28/200\n",
      "42964/42964 [==============================] - 15s 358us/step - loss: 0.1709 - categorical_accuracy: 0.9077 - val_loss: 0.1401 - val_categorical_accuracy: 0.9180\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.14224 to 0.14013, saving model to model.h5\n",
      "Epoch 29/200\n",
      "42964/42964 [==============================] - 16s 361us/step - loss: 0.1767 - categorical_accuracy: 0.9047 - val_loss: 0.2417 - val_categorical_accuracy: 0.8959\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.14013\n",
      "Epoch 30/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1698 - categorical_accuracy: 0.9077 - val_loss: 0.1398 - val_categorical_accuracy: 0.9159\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.14013 to 0.13982, saving model to model.h5\n",
      "Epoch 31/200\n",
      "42964/42964 [==============================] - 16s 361us/step - loss: 0.1649 - categorical_accuracy: 0.9082 - val_loss: 0.1388 - val_categorical_accuracy: 0.9157\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.13982 to 0.13881, saving model to model.h5\n",
      "Epoch 32/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1587 - categorical_accuracy: 0.9101 - val_loss: 0.1441 - val_categorical_accuracy: 0.9147\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.13881\n",
      "Epoch 33/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1594 - categorical_accuracy: 0.9104 - val_loss: 0.1395 - val_categorical_accuracy: 0.9181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: val_loss did not improve from 0.13881\n",
      "Epoch 34/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1599 - categorical_accuracy: 0.9108 - val_loss: 0.1364 - val_categorical_accuracy: 0.9148\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.13881 to 0.13644, saving model to model.h5\n",
      "Epoch 35/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1600 - categorical_accuracy: 0.9129 - val_loss: 0.1401 - val_categorical_accuracy: 0.9134\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.13644\n",
      "Epoch 36/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1499 - categorical_accuracy: 0.9132 - val_loss: 0.1341 - val_categorical_accuracy: 0.9165\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.13644 to 0.13405, saving model to model.h5\n",
      "Epoch 37/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1554 - categorical_accuracy: 0.9141 - val_loss: 0.1380 - val_categorical_accuracy: 0.9186\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.13405\n",
      "Epoch 38/200\n",
      "42964/42964 [==============================] - 15s 359us/step - loss: 0.1578 - categorical_accuracy: 0.9120 - val_loss: 0.1464 - val_categorical_accuracy: 0.9156\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.13405\n",
      "Epoch 39/200\n",
      "42964/42964 [==============================] - 15s 358us/step - loss: 0.1476 - categorical_accuracy: 0.9154 - val_loss: 0.1338 - val_categorical_accuracy: 0.9180\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.13405 to 0.13382, saving model to model.h5\n",
      "Epoch 40/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1475 - categorical_accuracy: 0.9134 - val_loss: 0.1356 - val_categorical_accuracy: 0.9156\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.13382\n",
      "Epoch 41/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1477 - categorical_accuracy: 0.9141 - val_loss: 0.1341 - val_categorical_accuracy: 0.9137\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.13382\n",
      "Epoch 42/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1427 - categorical_accuracy: 0.9169 - val_loss: 0.1321 - val_categorical_accuracy: 0.9170\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.13382 to 0.13214, saving model to model.h5\n",
      "Epoch 43/200\n",
      "42964/42964 [==============================] - 15s 359us/step - loss: 0.1491 - categorical_accuracy: 0.9147 - val_loss: 0.1454 - val_categorical_accuracy: 0.9148\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.13214\n",
      "Epoch 44/200\n",
      "42964/42964 [==============================] - 15s 360us/step - loss: 0.1491 - categorical_accuracy: 0.9155 - val_loss: 0.1287 - val_categorical_accuracy: 0.9210\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.13214 to 0.12870, saving model to model.h5\n",
      "Epoch 45/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1420 - categorical_accuracy: 0.9151 - val_loss: 0.1335 - val_categorical_accuracy: 0.9171\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.12870\n",
      "Epoch 46/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1420 - categorical_accuracy: 0.9165 - val_loss: 0.1359 - val_categorical_accuracy: 0.9156\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.12870\n",
      "Epoch 47/200\n",
      "42964/42964 [==============================] - 16s 361us/step - loss: 0.1475 - categorical_accuracy: 0.9161 - val_loss: 0.1343 - val_categorical_accuracy: 0.9177\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.12870\n",
      "Epoch 48/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1407 - categorical_accuracy: 0.9163 - val_loss: 0.1334 - val_categorical_accuracy: 0.9165\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.12870\n",
      "Epoch 49/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1523 - categorical_accuracy: 0.9154 - val_loss: 0.1489 - val_categorical_accuracy: 0.9171\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.12870\n",
      "Epoch 50/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1421 - categorical_accuracy: 0.9187 - val_loss: 0.1549 - val_categorical_accuracy: 0.9135\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.12870\n",
      "Epoch 51/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1481 - categorical_accuracy: 0.9157 - val_loss: 0.1359 - val_categorical_accuracy: 0.9146\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.12870\n",
      "Epoch 52/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1375 - categorical_accuracy: 0.9181 - val_loss: 0.1324 - val_categorical_accuracy: 0.9186\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.12870\n",
      "Epoch 53/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1399 - categorical_accuracy: 0.9185 - val_loss: 0.1348 - val_categorical_accuracy: 0.9163\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.12870\n",
      "Epoch 54/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1385 - categorical_accuracy: 0.9186 - val_loss: 0.1372 - val_categorical_accuracy: 0.9151\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.12870\n",
      "Epoch 55/200\n",
      "42964/42964 [==============================] - 16s 361us/step - loss: 0.1334 - categorical_accuracy: 0.9191 - val_loss: 0.1330 - val_categorical_accuracy: 0.9148\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.12870\n",
      "Epoch 56/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1361 - categorical_accuracy: 0.9189 - val_loss: 0.1458 - val_categorical_accuracy: 0.9198\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.12870\n",
      "Epoch 57/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1432 - categorical_accuracy: 0.9178 - val_loss: 0.1504 - val_categorical_accuracy: 0.9198\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.12870\n",
      "Epoch 58/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1330 - categorical_accuracy: 0.9206 - val_loss: 0.1356 - val_categorical_accuracy: 0.9148\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.12870\n",
      "Epoch 59/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1365 - categorical_accuracy: 0.9200 - val_loss: 0.1329 - val_categorical_accuracy: 0.9198\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.12870\n",
      "Epoch 60/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1308 - categorical_accuracy: 0.9210 - val_loss: 0.1336 - val_categorical_accuracy: 0.9162\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.12870\n",
      "Epoch 61/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1329 - categorical_accuracy: 0.9187 - val_loss: 0.1340 - val_categorical_accuracy: 0.9197\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.12870\n",
      "Epoch 62/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1357 - categorical_accuracy: 0.9183 - val_loss: 0.1305 - val_categorical_accuracy: 0.9211\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.12870\n",
      "Epoch 63/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1380 - categorical_accuracy: 0.9196 - val_loss: 0.1343 - val_categorical_accuracy: 0.9145\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.12870\n",
      "Epoch 64/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1322 - categorical_accuracy: 0.9208 - val_loss: 0.1327 - val_categorical_accuracy: 0.9189\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.12870\n",
      "Epoch 65/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1298 - categorical_accuracy: 0.9205 - val_loss: 0.1399 - val_categorical_accuracy: 0.9142\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.12870\n",
      "Epoch 66/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1317 - categorical_accuracy: 0.9192 - val_loss: 0.1446 - val_categorical_accuracy: 0.9185\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.12870\n",
      "Epoch 67/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1373 - categorical_accuracy: 0.9177 - val_loss: 0.1326 - val_categorical_accuracy: 0.9204\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.12870\n",
      "Epoch 68/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1270 - categorical_accuracy: 0.9236 - val_loss: 0.1365 - val_categorical_accuracy: 0.9165\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.12870\n",
      "Epoch 69/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1287 - categorical_accuracy: 0.9213 - val_loss: 0.1435 - val_categorical_accuracy: 0.9151\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.12870\n",
      "Epoch 70/200\n",
      "42964/42964 [==============================] - 16s 368us/step - loss: 0.1301 - categorical_accuracy: 0.9212 - val_loss: 0.1342 - val_categorical_accuracy: 0.9164\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.12870\n",
      "Epoch 71/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1303 - categorical_accuracy: 0.9215 - val_loss: 0.1292 - val_categorical_accuracy: 0.9160\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.12870\n",
      "Epoch 72/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1353 - categorical_accuracy: 0.9229 - val_loss: 0.1362 - val_categorical_accuracy: 0.9212\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.12870\n",
      "Epoch 73/200\n",
      "42964/42964 [==============================] - 16s 369us/step - loss: 0.1267 - categorical_accuracy: 0.9219 - val_loss: 0.1346 - val_categorical_accuracy: 0.9179\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.12870\n",
      "Epoch 74/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1301 - categorical_accuracy: 0.9201 - val_loss: 0.1330 - val_categorical_accuracy: 0.9163\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.12870\n",
      "Epoch 75/200\n",
      "42964/42964 [==============================] - 16s 361us/step - loss: 0.1325 - categorical_accuracy: 0.9199 - val_loss: 0.1295 - val_categorical_accuracy: 0.9177\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.12870\n",
      "Epoch 76/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1274 - categorical_accuracy: 0.9224 - val_loss: 0.1466 - val_categorical_accuracy: 0.9155\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.12870\n",
      "Epoch 77/200\n",
      "42964/42964 [==============================] - 15s 360us/step - loss: 0.1267 - categorical_accuracy: 0.9223 - val_loss: 0.1402 - val_categorical_accuracy: 0.9162\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.12870\n",
      "Epoch 78/200\n",
      "42964/42964 [==============================] - 16s 368us/step - loss: 0.1289 - categorical_accuracy: 0.9214 - val_loss: 0.1321 - val_categorical_accuracy: 0.9149\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.12870\n",
      "Epoch 79/200\n",
      "42964/42964 [==============================] - 16s 371us/step - loss: 0.1280 - categorical_accuracy: 0.9234 - val_loss: 0.1386 - val_categorical_accuracy: 0.9159\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.12870\n",
      "Epoch 80/200\n",
      "42964/42964 [==============================] - 16s 366us/step - loss: 0.1243 - categorical_accuracy: 0.9225 - val_loss: 0.1340 - val_categorical_accuracy: 0.9159\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.12870\n",
      "Epoch 81/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1319 - categorical_accuracy: 0.9222 - val_loss: 0.1369 - val_categorical_accuracy: 0.9136\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.12870\n",
      "Epoch 82/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1247 - categorical_accuracy: 0.9214 - val_loss: 0.1365 - val_categorical_accuracy: 0.9140\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.12870\n",
      "Epoch 83/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1304 - categorical_accuracy: 0.9205 - val_loss: 0.1562 - val_categorical_accuracy: 0.9110\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.12870\n",
      "Epoch 84/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1260 - categorical_accuracy: 0.9212 - val_loss: 0.1359 - val_categorical_accuracy: 0.9127\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.12870\n",
      "Epoch 85/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1248 - categorical_accuracy: 0.9223 - val_loss: 0.1390 - val_categorical_accuracy: 0.9184\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.12870\n",
      "Epoch 86/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1230 - categorical_accuracy: 0.9236 - val_loss: 0.1412 - val_categorical_accuracy: 0.9147\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.12870\n",
      "Epoch 87/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1323 - categorical_accuracy: 0.9198 - val_loss: 0.1358 - val_categorical_accuracy: 0.9155\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.12870\n",
      "Epoch 88/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1283 - categorical_accuracy: 0.9214 - val_loss: 0.1339 - val_categorical_accuracy: 0.9158\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.12870\n",
      "Epoch 89/200\n",
      "42964/42964 [==============================] - 15s 360us/step - loss: 0.1224 - categorical_accuracy: 0.9243 - val_loss: 0.1336 - val_categorical_accuracy: 0.9144\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.12870\n",
      "Epoch 90/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1213 - categorical_accuracy: 0.9229 - val_loss: 0.1360 - val_categorical_accuracy: 0.9172\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.12870\n",
      "Epoch 91/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1310 - categorical_accuracy: 0.9221 - val_loss: 0.1323 - val_categorical_accuracy: 0.9171\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.12870\n",
      "Epoch 92/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1259 - categorical_accuracy: 0.9241 - val_loss: 0.1388 - val_categorical_accuracy: 0.9205\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.12870\n",
      "Epoch 93/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1262 - categorical_accuracy: 0.9222 - val_loss: 0.1425 - val_categorical_accuracy: 0.9151\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.12870\n",
      "Epoch 94/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1250 - categorical_accuracy: 0.9218 - val_loss: 0.1367 - val_categorical_accuracy: 0.9161\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.12870\n",
      "Epoch 95/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1268 - categorical_accuracy: 0.9215 - val_loss: 0.1368 - val_categorical_accuracy: 0.9150\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.12870\n",
      "Epoch 96/200\n",
      "42964/42964 [==============================] - 15s 360us/step - loss: 0.1239 - categorical_accuracy: 0.9234 - val_loss: 0.1319 - val_categorical_accuracy: 0.9163\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.12870\n",
      "Epoch 97/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1235 - categorical_accuracy: 0.9243 - val_loss: 0.1350 - val_categorical_accuracy: 0.9159\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.12870\n",
      "Epoch 98/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1231 - categorical_accuracy: 0.9231 - val_loss: 0.1515 - val_categorical_accuracy: 0.9134\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.12870\n",
      "Epoch 99/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1259 - categorical_accuracy: 0.9224 - val_loss: 0.1324 - val_categorical_accuracy: 0.9180\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.12870\n",
      "Epoch 100/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1206 - categorical_accuracy: 0.9237 - val_loss: 0.1514 - val_categorical_accuracy: 0.9133\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.12870\n",
      "Epoch 101/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1259 - categorical_accuracy: 0.9236 - val_loss: 0.1349 - val_categorical_accuracy: 0.9210\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.12870\n",
      "Epoch 102/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1290 - categorical_accuracy: 0.9233 - val_loss: 0.1362 - val_categorical_accuracy: 0.9175\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.12870\n",
      "Epoch 103/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1206 - categorical_accuracy: 0.9242 - val_loss: 0.1396 - val_categorical_accuracy: 0.9128\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.12870\n",
      "Epoch 104/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1237 - categorical_accuracy: 0.9238 - val_loss: 0.1390 - val_categorical_accuracy: 0.9208\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.12870\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1238 - categorical_accuracy: 0.9239 - val_loss: 0.1402 - val_categorical_accuracy: 0.9149\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.12870\n",
      "Epoch 106/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1228 - categorical_accuracy: 0.9238 - val_loss: 0.1418 - val_categorical_accuracy: 0.9159\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.12870\n",
      "Epoch 107/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1206 - categorical_accuracy: 0.9246 - val_loss: 0.1446 - val_categorical_accuracy: 0.9163\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.12870\n",
      "Epoch 108/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1225 - categorical_accuracy: 0.9244 - val_loss: 0.1371 - val_categorical_accuracy: 0.9187\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.12870\n",
      "Epoch 109/200\n",
      "42964/42964 [==============================] - 16s 366us/step - loss: 0.1264 - categorical_accuracy: 0.9222 - val_loss: 0.1359 - val_categorical_accuracy: 0.9211\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.12870\n",
      "Epoch 110/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1230 - categorical_accuracy: 0.9226 - val_loss: 0.1476 - val_categorical_accuracy: 0.9149\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.12870\n",
      "Epoch 111/200\n",
      "42964/42964 [==============================] - 16s 366us/step - loss: 0.1217 - categorical_accuracy: 0.9259 - val_loss: 0.1382 - val_categorical_accuracy: 0.9131\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.12870\n",
      "Epoch 112/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1193 - categorical_accuracy: 0.9257 - val_loss: 0.1401 - val_categorical_accuracy: 0.9205\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.12870\n",
      "Epoch 113/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1256 - categorical_accuracy: 0.9225 - val_loss: 0.1414 - val_categorical_accuracy: 0.9203\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.12870\n",
      "Epoch 114/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1244 - categorical_accuracy: 0.9240 - val_loss: 0.1394 - val_categorical_accuracy: 0.9154\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.12870\n",
      "Epoch 115/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1189 - categorical_accuracy: 0.9241 - val_loss: 0.1382 - val_categorical_accuracy: 0.9173\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.12870\n",
      "Epoch 116/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1224 - categorical_accuracy: 0.9240 - val_loss: 0.1428 - val_categorical_accuracy: 0.9182\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.12870\n",
      "Epoch 117/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1191 - categorical_accuracy: 0.9237 - val_loss: 0.1386 - val_categorical_accuracy: 0.9133\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.12870\n",
      "Epoch 118/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1220 - categorical_accuracy: 0.9236 - val_loss: 0.1439 - val_categorical_accuracy: 0.9171\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.12870\n",
      "Epoch 119/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1254 - categorical_accuracy: 0.9228 - val_loss: 0.1450 - val_categorical_accuracy: 0.9158\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.12870\n",
      "Epoch 120/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1202 - categorical_accuracy: 0.9249 - val_loss: 0.1371 - val_categorical_accuracy: 0.9122\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.12870\n",
      "Epoch 121/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1239 - categorical_accuracy: 0.9242 - val_loss: 0.1399 - val_categorical_accuracy: 0.9168\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.12870\n",
      "Epoch 122/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1222 - categorical_accuracy: 0.9268 - val_loss: 0.1415 - val_categorical_accuracy: 0.9169\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.12870\n",
      "Epoch 123/200\n",
      "42964/42964 [==============================] - 16s 361us/step - loss: 0.1228 - categorical_accuracy: 0.9245 - val_loss: 0.1543 - val_categorical_accuracy: 0.9125\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.12870\n",
      "Epoch 124/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1199 - categorical_accuracy: 0.9250 - val_loss: 0.1456 - val_categorical_accuracy: 0.9135\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.12870\n",
      "Epoch 125/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1235 - categorical_accuracy: 0.9250 - val_loss: 0.1522 - val_categorical_accuracy: 0.9106\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.12870\n",
      "Epoch 126/200\n",
      "42964/42964 [==============================] - 16s 367us/step - loss: 0.1216 - categorical_accuracy: 0.9239 - val_loss: 0.1400 - val_categorical_accuracy: 0.9132\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.12870\n",
      "Epoch 127/200\n",
      "42964/42964 [==============================] - 16s 369us/step - loss: 0.1173 - categorical_accuracy: 0.9258 - val_loss: 0.1458 - val_categorical_accuracy: 0.9186\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.12870\n",
      "Epoch 128/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1200 - categorical_accuracy: 0.9252 - val_loss: 0.1403 - val_categorical_accuracy: 0.9118\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.12870\n",
      "Epoch 129/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1258 - categorical_accuracy: 0.9224 - val_loss: 0.1398 - val_categorical_accuracy: 0.9205\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.12870\n",
      "Epoch 130/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1203 - categorical_accuracy: 0.9233 - val_loss: 0.1460 - val_categorical_accuracy: 0.9151\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.12870\n",
      "Epoch 131/200\n",
      "42964/42964 [==============================] - 15s 361us/step - loss: 0.1180 - categorical_accuracy: 0.9249 - val_loss: 0.1383 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.12870\n",
      "Epoch 132/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1253 - categorical_accuracy: 0.9242 - val_loss: 0.1387 - val_categorical_accuracy: 0.9122\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.12870\n",
      "Epoch 133/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1181 - categorical_accuracy: 0.9262 - val_loss: 0.1388 - val_categorical_accuracy: 0.9158\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.12870\n",
      "Epoch 134/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1196 - categorical_accuracy: 0.9257 - val_loss: 0.1452 - val_categorical_accuracy: 0.9129\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.12870\n",
      "Epoch 135/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1201 - categorical_accuracy: 0.9258 - val_loss: 0.1444 - val_categorical_accuracy: 0.9167\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.12870\n",
      "Epoch 136/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1191 - categorical_accuracy: 0.9246 - val_loss: 0.1399 - val_categorical_accuracy: 0.9206\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.12870\n",
      "Epoch 137/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1157 - categorical_accuracy: 0.9268 - val_loss: 0.1397 - val_categorical_accuracy: 0.9211\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.12870\n",
      "Epoch 138/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1188 - categorical_accuracy: 0.9248 - val_loss: 0.1476 - val_categorical_accuracy: 0.9153\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.12870\n",
      "Epoch 139/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1225 - categorical_accuracy: 0.9242 - val_loss: 0.1818 - val_categorical_accuracy: 0.9102\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.12870\n",
      "Epoch 140/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1239 - categorical_accuracy: 0.9264 - val_loss: 0.1398 - val_categorical_accuracy: 0.9185\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.12870\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1211 - categorical_accuracy: 0.9229 - val_loss: 0.1652 - val_categorical_accuracy: 0.9097\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.12870\n",
      "Epoch 142/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1201 - categorical_accuracy: 0.9245 - val_loss: 0.1427 - val_categorical_accuracy: 0.9134\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.12870\n",
      "Epoch 143/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1182 - categorical_accuracy: 0.9257 - val_loss: 0.1467 - val_categorical_accuracy: 0.9164\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.12870\n",
      "Epoch 144/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1197 - categorical_accuracy: 0.9251 - val_loss: 0.1471 - val_categorical_accuracy: 0.9160\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.12870\n",
      "Epoch 145/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1242 - categorical_accuracy: 0.9253 - val_loss: 0.1430 - val_categorical_accuracy: 0.9117\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.12870\n",
      "Epoch 146/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1185 - categorical_accuracy: 0.9256 - val_loss: 0.1375 - val_categorical_accuracy: 0.9192\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.12870\n",
      "Epoch 147/200\n",
      "42964/42964 [==============================] - 15s 360us/step - loss: 0.1196 - categorical_accuracy: 0.9250 - val_loss: 0.1452 - val_categorical_accuracy: 0.9196\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.12870\n",
      "Epoch 148/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1207 - categorical_accuracy: 0.9251 - val_loss: 0.1463 - val_categorical_accuracy: 0.9152\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.12870\n",
      "Epoch 149/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1176 - categorical_accuracy: 0.9245 - val_loss: 0.1453 - val_categorical_accuracy: 0.9113\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.12870\n",
      "Epoch 150/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1189 - categorical_accuracy: 0.9254 - val_loss: 0.1526 - val_categorical_accuracy: 0.9109\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.12870\n",
      "Epoch 151/200\n",
      "42964/42964 [==============================] - 16s 361us/step - loss: 0.1192 - categorical_accuracy: 0.9275 - val_loss: 0.1638 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.12870\n",
      "Epoch 152/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1210 - categorical_accuracy: 0.9251 - val_loss: 0.1512 - val_categorical_accuracy: 0.9121\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.12870\n",
      "Epoch 153/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1175 - categorical_accuracy: 0.9268 - val_loss: 0.1475 - val_categorical_accuracy: 0.9127\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.12870\n",
      "Epoch 154/200\n",
      "42964/42964 [==============================] - 15s 361us/step - loss: 0.1208 - categorical_accuracy: 0.9254 - val_loss: 0.1453 - val_categorical_accuracy: 0.9148\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.12870\n",
      "Epoch 155/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1190 - categorical_accuracy: 0.9257 - val_loss: 0.1527 - val_categorical_accuracy: 0.9138\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.12870\n",
      "Epoch 156/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1178 - categorical_accuracy: 0.9266 - val_loss: 0.1424 - val_categorical_accuracy: 0.9141\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.12870\n",
      "Epoch 157/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1170 - categorical_accuracy: 0.9254 - val_loss: 0.1541 - val_categorical_accuracy: 0.9135\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.12870\n",
      "Epoch 158/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1255 - categorical_accuracy: 0.9241 - val_loss: 0.1473 - val_categorical_accuracy: 0.9142\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.12870\n",
      "Epoch 159/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1212 - categorical_accuracy: 0.9259 - val_loss: 0.1491 - val_categorical_accuracy: 0.9120\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.12870\n",
      "Epoch 160/200\n",
      "42964/42964 [==============================] - 16s 361us/step - loss: 0.1192 - categorical_accuracy: 0.9262 - val_loss: 0.1471 - val_categorical_accuracy: 0.9124\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.12870\n",
      "Epoch 161/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1184 - categorical_accuracy: 0.9244 - val_loss: 0.1637 - val_categorical_accuracy: 0.9097\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.12870\n",
      "Epoch 162/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1199 - categorical_accuracy: 0.9261 - val_loss: 0.1473 - val_categorical_accuracy: 0.9084\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.12870\n",
      "Epoch 163/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1172 - categorical_accuracy: 0.9248 - val_loss: 0.1493 - val_categorical_accuracy: 0.9090\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.12870\n",
      "Epoch 164/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1185 - categorical_accuracy: 0.9249 - val_loss: 0.1457 - val_categorical_accuracy: 0.9132\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.12870\n",
      "Epoch 165/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1166 - categorical_accuracy: 0.9270 - val_loss: 0.1435 - val_categorical_accuracy: 0.9169\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.12870\n",
      "Epoch 166/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1182 - categorical_accuracy: 0.9259 - val_loss: 0.1481 - val_categorical_accuracy: 0.9201\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.12870\n",
      "Epoch 167/200\n",
      "42964/42964 [==============================] - 16s 361us/step - loss: 0.1272 - categorical_accuracy: 0.9241 - val_loss: 0.1563 - val_categorical_accuracy: 0.9181\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.12870\n",
      "Epoch 168/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1206 - categorical_accuracy: 0.9253 - val_loss: 0.1500 - val_categorical_accuracy: 0.9112\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.12870\n",
      "Epoch 169/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1185 - categorical_accuracy: 0.9275 - val_loss: 0.1506 - val_categorical_accuracy: 0.9181\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.12870\n",
      "Epoch 170/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1205 - categorical_accuracy: 0.9259 - val_loss: 0.1476 - val_categorical_accuracy: 0.9119\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.12870\n",
      "Epoch 171/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1159 - categorical_accuracy: 0.9267 - val_loss: 0.1442 - val_categorical_accuracy: 0.9134\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.12870\n",
      "Epoch 172/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1187 - categorical_accuracy: 0.9253 - val_loss: 0.1484 - val_categorical_accuracy: 0.9173\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.12870\n",
      "Epoch 173/200\n",
      "42964/42964 [==============================] - 15s 360us/step - loss: 0.1153 - categorical_accuracy: 0.9287 - val_loss: 0.1521 - val_categorical_accuracy: 0.9131\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.12870\n",
      "Epoch 174/200\n",
      "42964/42964 [==============================] - 16s 361us/step - loss: 0.1217 - categorical_accuracy: 0.9256 - val_loss: 0.1486 - val_categorical_accuracy: 0.9150\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.12870\n",
      "Epoch 175/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1170 - categorical_accuracy: 0.9254 - val_loss: 0.1497 - val_categorical_accuracy: 0.9094\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.12870\n",
      "Epoch 176/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1154 - categorical_accuracy: 0.9273 - val_loss: 0.1486 - val_categorical_accuracy: 0.9130\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.12870\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1185 - categorical_accuracy: 0.9250 - val_loss: 0.1507 - val_categorical_accuracy: 0.9141\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.12870\n",
      "Epoch 178/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1180 - categorical_accuracy: 0.9259 - val_loss: 0.1572 - val_categorical_accuracy: 0.9161\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.12870\n",
      "Epoch 179/200\n",
      "42964/42964 [==============================] - 16s 376us/step - loss: 0.1140 - categorical_accuracy: 0.9275 - val_loss: 0.1543 - val_categorical_accuracy: 0.9182\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.12870\n",
      "Epoch 180/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1164 - categorical_accuracy: 0.9261 - val_loss: 0.1503 - val_categorical_accuracy: 0.9136\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.12870\n",
      "Epoch 181/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1248 - categorical_accuracy: 0.9251 - val_loss: 0.1520 - val_categorical_accuracy: 0.9132\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.12870\n",
      "Epoch 182/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1210 - categorical_accuracy: 0.9238 - val_loss: 0.1478 - val_categorical_accuracy: 0.9126\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.12870\n",
      "Epoch 183/200\n",
      "42964/42964 [==============================] - 16s 373us/step - loss: 0.1168 - categorical_accuracy: 0.9267 - val_loss: 0.1483 - val_categorical_accuracy: 0.9140\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.12870\n",
      "Epoch 184/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1150 - categorical_accuracy: 0.9259 - val_loss: 0.1555 - val_categorical_accuracy: 0.9190\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.12870\n",
      "Epoch 185/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1223 - categorical_accuracy: 0.9245 - val_loss: 0.1495 - val_categorical_accuracy: 0.9131\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.12870\n",
      "Epoch 186/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1160 - categorical_accuracy: 0.9257 - val_loss: 0.1519 - val_categorical_accuracy: 0.9082\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.12870\n",
      "Epoch 187/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1156 - categorical_accuracy: 0.9263 - val_loss: 0.1484 - val_categorical_accuracy: 0.9171\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.12870\n",
      "Epoch 188/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1202 - categorical_accuracy: 0.9258 - val_loss: 0.1569 - val_categorical_accuracy: 0.9089\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.12870\n",
      "Epoch 189/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1164 - categorical_accuracy: 0.9262 - val_loss: 0.1592 - val_categorical_accuracy: 0.9094\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.12870\n",
      "Epoch 190/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1149 - categorical_accuracy: 0.9258 - val_loss: 0.1569 - val_categorical_accuracy: 0.9154\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.12870\n",
      "Epoch 191/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1161 - categorical_accuracy: 0.9271 - val_loss: 0.1722 - val_categorical_accuracy: 0.9058\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.12870\n",
      "Epoch 192/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1243 - categorical_accuracy: 0.9265 - val_loss: 0.1587 - val_categorical_accuracy: 0.9096\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.12870\n",
      "Epoch 193/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1192 - categorical_accuracy: 0.9261 - val_loss: 0.1588 - val_categorical_accuracy: 0.9101\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.12870\n",
      "Epoch 194/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1193 - categorical_accuracy: 0.9258 - val_loss: 0.1476 - val_categorical_accuracy: 0.9080\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.12870\n",
      "Epoch 195/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1168 - categorical_accuracy: 0.9265 - val_loss: 0.1516 - val_categorical_accuracy: 0.9154\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.12870\n",
      "Epoch 196/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1150 - categorical_accuracy: 0.9256 - val_loss: 0.1636 - val_categorical_accuracy: 0.9147\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.12870\n",
      "Epoch 197/200\n",
      "42964/42964 [==============================] - 16s 362us/step - loss: 0.1211 - categorical_accuracy: 0.9264 - val_loss: 0.1679 - val_categorical_accuracy: 0.9117\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.12870\n",
      "Epoch 198/200\n",
      "42964/42964 [==============================] - 16s 364us/step - loss: 0.1194 - categorical_accuracy: 0.9274 - val_loss: 0.1510 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.12870\n",
      "Epoch 199/200\n",
      "42964/42964 [==============================] - 16s 365us/step - loss: 0.1195 - categorical_accuracy: 0.9263 - val_loss: 0.1547 - val_categorical_accuracy: 0.9094\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.12870\n",
      "Epoch 200/200\n",
      "42964/42964 [==============================] - 16s 363us/step - loss: 0.1185 - categorical_accuracy: 0.9274 - val_loss: 0.1472 - val_categorical_accuracy: 0.9058\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.12870\n"
     ]
    }
   ],
   "source": [
    "filename = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "hist = model.fit(train_X, train_Y, epochs = 200,  batch_size = 32, validation_data = (val_X, val_Y), callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(text):\n",
    "    clean = re.sub(r'[^ а-я А-Я 0-9]', \" \", text)\n",
    "    test_word = word_tokenize(clean)\n",
    "    test_word = [w.lower() for w in test_word]\n",
    "    \n",
    "    stopwords = nltk.corpus.stopwords.words(\"russian\")\n",
    "    newStopWords = ['скидки','скидкой','кешбек','кб','кэшбэк','кэшбек', 'кэшбек', 'кэш', 'кб', \n",
    "                    'кеш', 'кешбек', 'кэшбэк', 'cashback', 'ceshback', 'cashbak', 'cashbac,', 'ceshbak', 'ceshbac', \n",
    "                   '%', 'проц', 'п', 'пр', 'працентов', 'прац', 'працентав', 'percents', 'procents',\n",
    "                   'тыс', 'тыр', 'к', 'т', 'тысяч', 'тыщ', 'кэсов', 'косарей', 'thousands', ' 000',\n",
    "                   \"процентов\", \"рассрочка\", \"рассрочку\", \"кредит\", 'р', 'руб', 'рублей', 'rub', 'р.', 'roubles']\n",
    "    stopwords.extend(newStopWords)\n",
    "        \n",
    "    m = Mystem()\n",
    "    test_word = [m.lemmatize(w)[0] for w in test_word if not w in stopwords] \n",
    "#     print(test_word)\n",
    "    test_ls = word_tokenizer.texts_to_sequences(test_word)\n",
    "\n",
    "    #Check for unknown words\n",
    "    if [] in test_ls:\n",
    "        test_ls = list(filter(None, test_ls))\n",
    "    \n",
    "    test_ls = np.array(test_ls).reshape(1, len(test_ls))\n",
    " \n",
    "    x = padding_doc(test_ls, max_l)\n",
    "  \n",
    "    pred = model.predict_proba(x)\n",
    "    return pred\n",
    "\n",
    "# Возвращаем самый вероятный интент\n",
    "def get_final_output(pred, classes, to_print = False):\n",
    "    predictions = pred[0]\n",
    " \n",
    "    classes = np.array(classes)\n",
    "    ids = np.argsort(-predictions)\n",
    "    classes = classes[ids]\n",
    "    predictions = -np.sort(-predictions)\n",
    " \n",
    "    if to_print:\n",
    "        for i in range(pred.shape[1]):\n",
    "            print(\"%s has confidence = %s\" % (classes[i], (predictions[i])))\n",
    "    return(classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверочка\n",
    "texts = [\n",
    "    'Купить яблочки зеленые в рассрочку',\n",
    "    \"Куртка зимняя лыжная\",\n",
    "    \"кроссовки найк со скидкой и кэшбеком 5%\",\n",
    "    \"морская капуста на дом\",\n",
    "    \"доставка суши в Москве до 1000 рублей с кэшбеком\"\n",
    "]\n",
    "df = pd.DataFrame(columns=[\"QUERY\", \"INTENT\"])\n",
    "for text in texts:\n",
    "    pred = predictions(text)\n",
    "    df = df.append([{\"QUERY\": text, \"INTENT\": get_final_output(pred, unique_intent)}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUERY</th>\n",
       "      <th>INTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Купить яблочки зеленые в рассрочку</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Куртка зимняя лыжная</td>\n",
       "      <td>buy_sportswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>кроссовки найк со скидкой и кэшбеком 5%</td>\n",
       "      <td>buy_sportswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>морская капуста на дом</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>доставка суши в Москве до 1000 рублей с кэшбеком</td>\n",
       "      <td>order_food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              QUERY              INTENT\n",
       "0                Купить яблочки зеленые в рассрочку  buy_or_order_goods\n",
       "0                              Куртка зимняя лыжная      buy_sportswear\n",
       "0           кроссовки найк со скидкой и кэшбеком 5%      buy_sportswear\n",
       "0                            морская капуста на дом  buy_or_order_goods\n",
       "0  доставка суши в Москве до 1000 рублей с кэшбеком          order_food"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение файла с запросами, у которых интент не определён на предыдущем этапе при помощи поиска по словарям\n",
    "lst = pd.read_csv('hackaton/bad_intents.csv')\n",
    "lst = lst.QUERY\n",
    "df = pd.DataFrame(columns=[\"QUERY\", \"INTENT\"])\n",
    "for text in lst:\n",
    "    pred = predictions(text)\n",
    "    df = df.append([{\"QUERY\": text, \"INTENT\": get_final_output(pred, unique_intent)}])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем распознанное\n",
    "df.to_csv('hackaton/lstm_intents.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUERY</th>\n",
       "      <th>INTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>кроссофки для бега хочу купить с минимальным к...</td>\n",
       "      <td>buy_sport_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>очки для плавания купить с максимальным кэшбэком</td>\n",
       "      <td>get_service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>купить мороженное по самой низкой цене</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>со скидкой макдональдс</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>где приобрести мороженное спецпредложение</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хоккейное снаряжение заказать спецпредложение</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>где приобрести фрукты с доставкой</td>\n",
       "      <td>buy_equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ананасы заказать скидка</td>\n",
       "      <td>order_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>где можно поесть</td>\n",
       "      <td>order_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>мраморная говядина</td>\n",
       "      <td>buy_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>фрукты хочу купить с максимальным кэшбеком</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хочу купить хоккейную клюшку</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>беговые мяч для пилатеса где приобрести со ски...</td>\n",
       "      <td>buy_sport_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>где где приобрести суши по акции</td>\n",
       "      <td>buy_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хоккейное снаряжение хочу с максимальным кешбеком</td>\n",
       "      <td>buy_sportswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>скидки в ресторанах</td>\n",
       "      <td>buy_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>беговые горный велосипед купить со скидкой</td>\n",
       "      <td>buy_sport_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>очки для плавания купить с максимальным кэшбэком</td>\n",
       "      <td>get_service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>свежие суши купить</td>\n",
       "      <td>buy_sport_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>баскетбольное кольцо где можно купить</td>\n",
       "      <td>buy_sport_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>купить купить мяч для пилатеса burton</td>\n",
       "      <td>buy_sport_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>где скушать яблочный пирог</td>\n",
       "      <td>buy_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>где можно купить биг мак с доставкой</td>\n",
       "      <td>buy_equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>где заказать мясо с максимальной скидкой</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>недорогой беговой тренажер</td>\n",
       "      <td>buy_equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>заказать 10 штук яиц</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>с максимальным кешбеком макдональдс</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>фрукты заказать скидка</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>где приобрести беговые лыжи до 15 тысяч дешево</td>\n",
       "      <td>buy_equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>рестораны поблизости с с максимальной скидкойом</td>\n",
       "      <td>buy_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хочу купить дартс</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>купить одежду для тренажерного зала</td>\n",
       "      <td>buy_equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>заказать перчатки для велоспорта с спецпредлож...</td>\n",
       "      <td>buy_sportswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>пицца где дешевле чем у других</td>\n",
       "      <td>buy_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хочу купить можно купить хоккейную клюшку</td>\n",
       "      <td>buy_equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>заказать перчатки для велоспорта дешевле</td>\n",
       "      <td>buy_sportswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>мяч для регби хочу купить с максимальным кэшбэком</td>\n",
       "      <td>buy_equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вок где приобрести</td>\n",
       "      <td>buy_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>мраморная говядина</td>\n",
       "      <td>buy_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>где суши</td>\n",
       "      <td>buy_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хочу лыжи очень дешево</td>\n",
       "      <td>buy_equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>мяч для пилатеса addidas</td>\n",
       "      <td>get_service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>нужны боксерские груши в новый зал бокса</td>\n",
       "      <td>get_service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>яблочный пирог где приобрести</td>\n",
       "      <td>buy_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>очки для плавания хочу с максимальным кэшбэком</td>\n",
       "      <td>buy_sportswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>где коньки burton</td>\n",
       "      <td>buy_equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>с кешбеком макдональдс</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>где заказать ананасы очень дешево</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>рестораны поблизости с дешевоом</td>\n",
       "      <td>buy_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>рестораны поблизости с с максимальной скидкойом</td>\n",
       "      <td>buy_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хочу можно найти велосипед горный 2015 по само...</td>\n",
       "      <td>buy_sport_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>где хочу лыжную куртку с мембраной</td>\n",
       "      <td>buy_sportswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>по самой низкой цене макдональдс</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хочу купить хоккейную клюшку</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>купить мороженное по акции</td>\n",
       "      <td>buy_or_order_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хочу купить беговые лыжи до 15 тысяч с максима...</td>\n",
       "      <td>buy_equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>где одежду для сноуборда с максимальным дешевлеом</td>\n",
       "      <td>buy_equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>где беговые лыжи до 15 тысяч с максимальным ке...</td>\n",
       "      <td>buy_equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>очки для плавания хочу купить с максимальным к...</td>\n",
       "      <td>get_service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>заказать сладкий стол дешевле чем у других</td>\n",
       "      <td>buy_food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                QUERY              INTENT\n",
       "0   кроссофки для бега хочу купить с минимальным к...      buy_sport_food\n",
       "0    очки для плавания купить с максимальным кэшбэком         get_service\n",
       "0              купить мороженное по самой низкой цене  buy_or_order_goods\n",
       "0                             со скидкой макдональдс   buy_or_order_goods\n",
       "0           где приобрести мороженное спецпредложение  buy_or_order_goods\n",
       "0       хоккейное снаряжение заказать спецпредложение  buy_or_order_goods\n",
       "0                   где приобрести фрукты с доставкой       buy_equipment\n",
       "0                             ананасы заказать скидка          order_food\n",
       "0                                    где можно поесть          order_food\n",
       "0                                 мраморная говядина             buy_food\n",
       "0          фрукты хочу купить с максимальным кэшбеком  buy_or_order_goods\n",
       "0                        хочу купить хоккейную клюшку  buy_or_order_goods\n",
       "0   беговые мяч для пилатеса где приобрести со ски...      buy_sport_food\n",
       "0                    где где приобрести суши по акции            buy_food\n",
       "0   хоккейное снаряжение хочу с максимальным кешбеком      buy_sportswear\n",
       "0                                 скидки в ресторанах            buy_food\n",
       "0          беговые горный велосипед купить со скидкой      buy_sport_food\n",
       "0    очки для плавания купить с максимальным кэшбэком         get_service\n",
       "0                                  свежие суши купить      buy_sport_food\n",
       "0               баскетбольное кольцо где можно купить      buy_sport_food\n",
       "0               купить купить мяч для пилатеса burton      buy_sport_food\n",
       "0                          где скушать яблочный пирог            buy_food\n",
       "0                где можно купить биг мак с доставкой       buy_equipment\n",
       "0            где заказать мясо с максимальной скидкой  buy_or_order_goods\n",
       "0                         недорогой беговой тренажер        buy_equipment\n",
       "0                                заказать 10 штук яиц  buy_or_order_goods\n",
       "0                с максимальным кешбеком макдональдс   buy_or_order_goods\n",
       "0                              фрукты заказать скидка  buy_or_order_goods\n",
       "0      где приобрести беговые лыжи до 15 тысяч дешево       buy_equipment\n",
       "0     рестораны поблизости с с максимальной скидкойом            buy_food\n",
       "..                                                ...                 ...\n",
       "0                                   хочу купить дартс  buy_or_order_goods\n",
       "0                 купить одежду для тренажерного зала       buy_equipment\n",
       "0   заказать перчатки для велоспорта с спецпредлож...      buy_sportswear\n",
       "0                      пицца где дешевле чем у других            buy_food\n",
       "0           хочу купить можно купить хоккейную клюшку       buy_equipment\n",
       "0            заказать перчатки для велоспорта дешевле      buy_sportswear\n",
       "0   мяч для регби хочу купить с максимальным кэшбэком       buy_equipment\n",
       "0                                  вок где приобрести            buy_food\n",
       "0                                 мраморная говядина             buy_food\n",
       "0                                            где суши            buy_food\n",
       "0                              хочу лыжи очень дешево       buy_equipment\n",
       "0                            мяч для пилатеса addidas         get_service\n",
       "0            нужны боксерские груши в новый зал бокса         get_service\n",
       "0                       яблочный пирог где приобрести            buy_food\n",
       "0      очки для плавания хочу с максимальным кэшбэком      buy_sportswear\n",
       "0                                   где коньки burton       buy_equipment\n",
       "0                             с кешбеком макдональдс   buy_or_order_goods\n",
       "0                   где заказать ананасы очень дешево  buy_or_order_goods\n",
       "0                     рестораны поблизости с дешевоом            buy_food\n",
       "0     рестораны поблизости с с максимальной скидкойом            buy_food\n",
       "0   хочу можно найти велосипед горный 2015 по само...      buy_sport_food\n",
       "0                  где хочу лыжную куртку с мембраной      buy_sportswear\n",
       "0                   по самой низкой цене макдональдс   buy_or_order_goods\n",
       "0                        хочу купить хоккейную клюшку  buy_or_order_goods\n",
       "0                          купить мороженное по акции  buy_or_order_goods\n",
       "0   хочу купить беговые лыжи до 15 тысяч с максима...       buy_equipment\n",
       "0   где одежду для сноуборда с максимальным дешевлеом       buy_equipment\n",
       "0   где беговые лыжи до 15 тысяч с максимальным ке...       buy_equipment\n",
       "0   очки для плавания хочу купить с максимальным к...         get_service\n",
       "0          заказать сладкий стол дешевле чем у других            buy_food\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
