{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import nltk\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load food offers dictionaries\n",
    "df_buy_food = pd.read_csv(\"cafe.csv\")\n",
    "df_order_food = pd.read_csv(\"food_order.csv\")\n",
    "df_buy_or_order_goods_dict = pd.read_csv(\"goods.csv\")\n",
    "\n",
    "#Create dictionary with intents related to food\n",
    "food_dicts = {'buy_food': df_buy_food, 'order_food': df_order_food, 'buy_or_order_goods': df_buy_or_order_goods_dict}\n",
    "\n",
    "#Load sport offers dictionaries\n",
    "df_buy_sportswear = pd.read_csv(\"sportswear_brands.csv\")\n",
    "df_buy_equipment = pd.read_csv(\"sports_equipment.csv\")\n",
    "df_buy_sport_food = pd.read_csv(\"sports_nutrition.csv\")\n",
    "df_rent_equipment = pd.read_csv(\"sports_equipment_rental.csv\")\n",
    "df_get_train = pd.read_csv(\"services_of_instructors.csv\")\n",
    "df_get_service = pd.read_csv(\"services_of_clubs.csv\")\n",
    "\n",
    "#Create dictionary with intents related to sport\n",
    "sport_dicts = {'buy_sportswear': df_buy_sportswear, 'buy_equipment': df_buy_equipment, 'buy_sport_food': df_buy_sport_food, \n",
    "               'rent_equipment': df_rent_equipment, 'get_train': df_get_train, 'get_service': df_get_service}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for data processing\n",
    "def processing_intents_dicts(dictionary):\n",
    "    for f in dictionary.keys():\n",
    "        #lemmatize words in query\n",
    "        current_df = dictionary.get(f)\n",
    "        vals = np.array(current_df['NAME'])\n",
    "        lemmatized = []\n",
    "        m = Mystem()\n",
    "        for word in vals:\n",
    "            str_lem = \"\"\n",
    "            for lem_word in m.lemmatize(word)[:-1]:\n",
    "                str_lem += lem_word\n",
    "            lemmatized.append(str_lem)\n",
    "            \n",
    "            \n",
    "        #Get unique words                \n",
    "        series = pd.Series(lemmatized).str.lower().unique()\n",
    "        df_new = pd.DataFrame({'NAME': series})\n",
    "        df_new.to_csv(\"new/\" + f + \"_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing dictionaries using helper function\n",
    "processing_intents_dicts(food_dicts)\n",
    "processing_intents_dicts(sport_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load food offers dictionaries\n",
    "df_buy_food = pd.read_csv(\"new/buy_food_new.csv\")\n",
    "df_order_food = pd.read_csv(\"new/order_food_new.csv\")\n",
    "df_buy_or_order_goods_dict = pd.read_csv(\"new/buy_or_order_goods_new.csv\")\n",
    "\n",
    "#Load sport offers dictionaries\n",
    "df_buy_sportswear = pd.read_csv(\"new/buy_sportswear_new.csv\")\n",
    "df_buy_equipment = pd.read_csv(\"new/buy_equipment_new.csv\")\n",
    "df_buy_sport_food = pd.read_csv(\"new/buy_sport_food_new.csv\")\n",
    "df_rent_equipment = pd.read_csv(\"new/rent_equipment_new.csv\")\n",
    "df_get_train = pd.read_csv(\"new/get_train_new.csv\")\n",
    "df_get_service = pd.read_csv(\"new/get_service_new.csv\")\n",
    "\n",
    "#Create final food and sport dictionaries\n",
    "food_d = {'buy_food': df_buy_food, 'order_food': df_order_food, 'buy_or_order_goods': df_buy_or_order_goods_dict}\n",
    "sport_d = {'buy_sportswear': df_buy_sportswear, 'buy_equipment': df_buy_equipment, 'buy_sport_food': df_buy_sport_food, \n",
    "               'rent_equipment': df_rent_equipment, 'get_train': df_get_train, 'get_service': df_get_service}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for preclassification process using prepared dictionaries\n",
    "def intent_preclassification(query):\n",
    "    words = query.split(' ')\n",
    "    lem_words = []\n",
    "    lem_bigrm = []\n",
    "    lem_trigrm = []\n",
    "    \n",
    "    w = Mystem()\n",
    "    # Create bag of words in query\n",
    "    for word in words:\n",
    "        if len(w.lemmatize(word)) > 0:\n",
    "            lem_word = w.lemmatize(word)[0]\n",
    "        else:\n",
    "            lem_word = \"\"\n",
    "        lem_words.append(lem_word)\n",
    "        \n",
    "    bigrm = list(nltk.bigrams(lem_words))\n",
    "    \n",
    "    # Create bag of bigramms in query\n",
    "    for pair in bigrm:\n",
    "        str_bigr = pair[0] + \" \" + pair[1]\n",
    "        lem_bigrm.append(str_bigr)\n",
    "        \n",
    "    trigrm = list(nltk.trigrams(lem_words))\n",
    "    \n",
    "    # Create bag of trigramms in query\n",
    "    for triple in trigrm:\n",
    "        str_trpl = triple[0] + \" \" + triple[1] + \" \" + triple[2]\n",
    "        lem_trigrm.append(str_trpl)\n",
    "    \n",
    "    probs = {'buy_sportswear': 0, 'buy_equipment': 0, 'buy_sport_food': 0, \n",
    "               'rent_equipment': 0, 'get_train': 0, 'get_service': 0, 'buy_food' : 0, \n",
    "             'order_food': 0, 'buy_or_order_goods': 0 }\n",
    "    \n",
    "    def set_probs(list_of_words, dictionary):\n",
    "        for word in list_of_words:\n",
    "            for key in dictionary:\n",
    "                curr_dict = dictionary.get(key)\n",
    "                terms = np.array(curr_dict['NAME'])\n",
    "                if word in terms:\n",
    "                    probs[key] = probs.get(key) + 1\n",
    "                    \n",
    "    for dictionary in [sport_d, food_d]:\n",
    "        set_probs(lem_words, dictionary)\n",
    "        set_probs(lem_bigrm, dictionary)\n",
    "        set_probs(lem_trigrm, dictionary)\n",
    "\n",
    "    freq_intent = []\n",
    "    max_val = max(probs.values())\n",
    "    for key in probs:\n",
    "        if (probs.get(key) == max_val) and (max_val != 0):\n",
    "            freq_intent.append(key)\n",
    "    if len(freq_intent) == 0:\n",
    "        freq_intent.append('not_found')\n",
    "    return freq_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of intents, which parse well using preclassifier and save them to file\n",
    "queries = pd.read_csv(\"queries_final.csv\")\n",
    "queries_arr = queries.QUERY.values\n",
    "results_array = []\n",
    "queries_array = []\n",
    "bad_results_array = []\n",
    "bad_queries_array = []\n",
    "for query in queries_arr:\n",
    "    if (len(intent_preclassification(query)) == 1) and (intent_preclassification(query)[0] != 'not_found'):\n",
    "        queries_array.append(query)\n",
    "        results_array.append(intent_preclassification(query))\n",
    "    elif (len(intent_preclassification(query)) == 2):\n",
    "        queries_array.append(query)\n",
    "        results_array.append(intent_preclassification(query)[0])\n",
    "    elif (len(intent_preclassification(query)) > 1) or (intent_preclassification(query)[0] == 'not_found'):\n",
    "        bad_queries_array.append(query)\n",
    "        bad_results_array.append(intent_preclassification(query))\n",
    "#print(results_array)\n",
    "series1 = pd.Series(results_array)\n",
    "series2 = pd.Series(queries_array)\n",
    "df_new = pd.DataFrame({'QUERY': series2, 'INTENT': series1})\n",
    "df_new.to_csv(\"intents_by_preclassifier.csv\", index=False)\n",
    "\n",
    "series3 = pd.Series(bad_results_array)\n",
    "series4 = pd.Series(bad_queries_array)\n",
    "df_new = pd.DataFrame({'QUERY': series3, 'INTENT': series4})\n",
    "df_new.to_csv(\"bad_intents.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
